{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3:16:44"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec\n",
    "- converting words (strings of chars) to a **numeric vector representation of a word**\n",
    "- example: making vector representations out of words from Wikipedia\n",
    "\n",
    "- **word2vec** is a shallow, two-layer neural network \n",
    "    - accepts a text corpus as an input\n",
    "    - returns a set of vectors (also known as embeddings)\n",
    "    - each vector is a numeric representation of a given word\n",
    "- skipgram method\n",
    "    - defining a window of words around the focus word (**context**)\n",
    "    - the model goes through the corpus and checks which words fall within the defined windows (ie. one, two or three...) to help it learn the meaning of a word\n",
    "    - this allows the model to learn similar words (ie. colors...)\n",
    "- any n-dimensional vector can be plotted in a n-dimensional graph\n",
    "    - this provides insight into similarity of words (semantic relationship in the form of synonyms)\n",
    "    - **cosine similarity**\n",
    "        - two vectors are passed to a function \n",
    "        - cosine is calculated based on the angle between two vectors\n",
    "        - it returns a number between -1 and 1\n",
    "            - if the angle is close to zero, then the similarity score (cos(angle)) will be very close to 1\n",
    "            - if the angle is close to 180, the score will be close to 0 (no similarities)\n",
    "    - two vectors can be substracted from each other to look for word analogies (\"queen is to man what queen is to woman\")\n",
    "        - queen = king - man + woman \n",
    "        \n",
    "--------------------------------------\n",
    "\n",
    "#### using word2vec\n",
    "1. using pretrained embeddings\n",
    "    - a model that has been trained on some extremely large corpus of text\n",
    "    - generic word vectors out of the box\n",
    "    - more stable\n",
    "    \n",
    "2. train embeddings on our own data\n",
    "    - the result would be embeddings that are more tailored to a specific problem\n",
    "    - real-life: words are used differently depending on the channel, style, context etc.\n",
    "    - downside is a complicated training process and the vectors could not be as good if they are not trained on a large enough corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\dkarl\\anaconda3\\envs\\nlp_lipik\\lib\\site-packages (3.8.3)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\dkarl\\anaconda3\\envs\\nlp_lipik\\lib\\site-packages (from gensim) (1.19.2)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\dkarl\\anaconda3\\envs\\nlp_lipik\\lib\\site-packages (from gensim) (1.6.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\dkarl\\anaconda3\\envs\\nlp_lipik\\lib\\site-packages (from gensim) (1.9.0)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\users\\dkarl\\anaconda3\\envs\\nlp_lipik\\lib\\site-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied: bz2file in c:\\users\\dkarl\\anaconda3\\envs\\nlp_lipik\\lib\\site-packages (from smart-open>=1.8.1->gensim) (0.98)\n",
      "Requirement already satisfied: requests in c:\\users\\dkarl\\anaconda3\\envs\\nlp_lipik\\lib\\site-packages (from smart-open>=1.8.1->gensim) (2.25.1)\n",
      "Requirement already satisfied: boto3 in c:\\users\\dkarl\\anaconda3\\envs\\nlp_lipik\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.17.46)\n",
      "Requirement already satisfied: boto>=2.32 in c:\\users\\dkarl\\anaconda3\\envs\\nlp_lipik\\lib\\site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Requirement already satisfied: botocore<1.21.0,>=1.20.46 in c:\\users\\dkarl\\anaconda3\\envs\\nlp_lipik\\lib\\site-packages (from boto3->smart-open>=1.8.1->gensim) (1.20.73)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in c:\\users\\dkarl\\anaconda3\\envs\\nlp_lipik\\lib\\site-packages (from boto3->smart-open>=1.8.1->gensim) (0.3.6)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\users\\dkarl\\anaconda3\\envs\\nlp_lipik\\lib\\site-packages (from boto3->smart-open>=1.8.1->gensim) (0.10.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\users\\dkarl\\anaconda3\\envs\\nlp_lipik\\lib\\site-packages (from botocore<1.21.0,>=1.20.46->boto3->smart-open>=1.8.1->gensim) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\dkarl\\anaconda3\\envs\\nlp_lipik\\lib\\site-packages (from botocore<1.21.0,>=1.20.46->boto3->smart-open>=1.8.1->gensim) (2.8.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dkarl\\anaconda3\\envs\\nlp_lipik\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\dkarl\\anaconda3\\envs\\nlp_lipik\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\dkarl\\anaconda3\\envs\\nlp_lipik\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (4.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working with gensim\n",
    "1. loading pretrained word vectors\n",
    "2. exploring word vectors\n",
    "3. finding similar words based on pretrained word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "wiki_embeddings = api.load('glove-wiki-gigaword-100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.32307 , -0.87616 ,  0.21977 ,  0.25268 ,  0.22976 ,  0.7388  ,\n",
       "       -0.37954 , -0.35307 , -0.84369 , -1.1113  , -0.30266 ,  0.33178 ,\n",
       "       -0.25113 ,  0.30448 , -0.077491, -0.89815 ,  0.092496, -1.1407  ,\n",
       "       -0.58324 ,  0.66869 , -0.23122 , -0.95855 ,  0.28262 , -0.078848,\n",
       "        0.75315 ,  0.26584 ,  0.3422  , -0.33949 ,  0.95608 ,  0.065641,\n",
       "        0.45747 ,  0.39835 ,  0.57965 ,  0.39267 , -0.21851 ,  0.58795 ,\n",
       "       -0.55999 ,  0.63368 , -0.043983, -0.68731 , -0.37841 ,  0.38026 ,\n",
       "        0.61641 , -0.88269 , -0.12346 , -0.37928 , -0.38318 ,  0.23868 ,\n",
       "        0.6685  , -0.43321 , -0.11065 ,  0.081723,  1.1569  ,  0.78958 ,\n",
       "       -0.21223 , -2.3211  , -0.67806 ,  0.44561 ,  0.65707 ,  0.1045  ,\n",
       "        0.46217 ,  0.19912 ,  0.25802 ,  0.057194,  0.53443 , -0.43133 ,\n",
       "       -0.34311 ,  0.59789 , -0.58417 ,  0.068995,  0.23944 , -0.85181 ,\n",
       "        0.30379 , -0.34177 , -0.25746 , -0.031101, -0.16285 ,  0.45169 ,\n",
       "       -0.91627 ,  0.64521 ,  0.73281 , -0.22752 ,  0.30226 ,  0.044801,\n",
       "       -0.83741 ,  0.55006 , -0.52506 , -1.7357  ,  0.4751  , -0.70487 ,\n",
       "        0.056939, -0.7132  ,  0.089623,  0.41394 , -1.3363  , -0.61915 ,\n",
       "       -0.33089 , -0.52881 ,  0.16483 , -0.98878 ], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_embeddings['king']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('prince', 0.7682329416275024),\n",
       " ('queen', 0.7507690787315369),\n",
       " ('son', 0.7020887732505798),\n",
       " ('brother', 0.6985775232315063),\n",
       " ('monarch', 0.6977890729904175),\n",
       " ('throne', 0.691999077796936),\n",
       " ('kingdom', 0.6811410188674927),\n",
       " ('father', 0.680202841758728),\n",
       " ('emperor', 0.6712858080863953),\n",
       " ('ii', 0.6676074266433716)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_embeddings.most_similar('king')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training a model with gensim\n",
    "1. reading in the data\n",
    "2. cleaning up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-e5a54f71518f>:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  data = pd.read_csv('dataset/SMSSpamCollection.csv', sep='delimiter')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                                  text  \n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...  \n",
       "1                                                                        Ok lar... Joking wif u oni...  \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...  \n",
       "3                                                    U dun say so early hor... U c already then say...  \n",
       "4                                        Nah I don't think he goes to usf, he lives around here though  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "data = pd.read_csv('dataset/SMSSpamCollection.csv', sep='delimiter')\n",
    "messages = pd.DataFrame(columns=['label','text'])\n",
    "messages[['label','text']] = data['v1\\tv2'].str.split('\\t', expand=True)\n",
    "\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, only, in, bugis, great, world, la, buffet, cine, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>[ok, lar, joking, wif, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "      <td>[free, entry, in, wkly, comp, to, win, fa, cup, final, tkts, st, may, text, fa, to, to, receive,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>[dun, say, so, early, hor, already, then, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>[nah, don, think, he, goes, to, usf, he, lives, around, here, though]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                                  text  \\\n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...   \n",
       "1                                                                        Ok lar... Joking wif u oni...   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
       "3                                                    U dun say so early hor... U c already then say...   \n",
       "4                                        Nah I don't think he goes to usf, he lives around here though   \n",
       "\n",
       "                                                                                            text_clean  \n",
       "0  [go, until, jurong, point, crazy, available, only, in, bugis, great, world, la, buffet, cine, th...  \n",
       "1                                                                          [ok, lar, joking, wif, oni]  \n",
       "2  [free, entry, in, wkly, comp, to, win, fa, cup, final, tkts, st, may, text, fa, to, to, receive,...  \n",
       "3                                                       [dun, say, so, early, hor, already, then, say]  \n",
       "4                                [nah, don, think, he, goes, to, usf, he, lives, around, here, though]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gensim.utils.simple_preprocess \n",
    "# removes the stopwords, punctuations and cleans the text in lowercase\n",
    "messages['text_clean'] = messages['text'].apply(lambda x: gensim.utils.simple_preprocess(x))\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    messages['text_clean'],\n",
    "    messages['label'],\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the training model we pass:\n",
    "    # 1. the training data,\n",
    "    # 2. size of the vectors\n",
    "    # 3. window size - the defines the number of words that are looked into \n",
    "                    # before and after a single word \n",
    "                    # to define a CONTEXT for that word\n",
    "    # 4. min_count - the number of times a word MUST appear in the corpus in order to create a word vector \n",
    "\n",
    "w2v_model = gensim.models.Word2Vec(X_train, size=100, window=5, min_count=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.05539067e-02,  4.64578532e-02,  1.58831719e-02, -1.51924435e-02,\n",
       "       -1.13291442e-01, -1.97012946e-02,  1.01023382e-02, -1.54630365e-02,\n",
       "       -1.00295611e-01, -1.76381953e-02,  4.56879064e-02,  5.90193607e-02,\n",
       "       -1.76282059e-02,  5.12666032e-02, -1.76997688e-02, -6.50342479e-02,\n",
       "       -8.95903707e-02, -5.60897496e-03, -7.59827346e-02,  1.54406400e-02,\n",
       "       -9.32148248e-02, -7.01542292e-03,  4.20686416e-02, -2.78477930e-02,\n",
       "        7.73381768e-03, -9.56976637e-02,  5.03551811e-02, -2.49051861e-02,\n",
       "       -8.37319065e-03,  6.21041171e-02,  7.45661780e-02, -1.35712817e-01,\n",
       "       -5.44772595e-02,  7.02554360e-02, -4.79186699e-02,  5.52556142e-02,\n",
       "        1.14355095e-01,  4.17503230e-02, -3.59951966e-02, -6.00103056e-03,\n",
       "        2.77257916e-02,  1.89548545e-02,  8.28571990e-03, -1.81145072e-02,\n",
       "        8.20372999e-03,  5.79352602e-02, -2.57818811e-02, -1.20909847e-01,\n",
       "        3.94678079e-02,  9.33493939e-05, -1.24044605e-02,  4.10076082e-02,\n",
       "       -3.17845643e-02, -1.18648276e-01, -1.51634797e-01, -7.84648731e-02,\n",
       "        6.28388952e-03,  2.58223154e-02, -1.14659347e-01,  1.04884274e-01,\n",
       "       -3.42426971e-02, -6.85063715e-04,  2.74991877e-02,  6.75613713e-03,\n",
       "        5.61152548e-02, -1.36605855e-02, -1.39575019e-01, -4.35300022e-02,\n",
       "        1.34745479e-01, -2.37599500e-02, -1.38505235e-01, -2.60642469e-02,\n",
       "       -1.26244187e-01,  1.40959978e-01,  1.16360355e-02,  8.54154304e-02,\n",
       "        4.23979759e-02, -3.57350893e-02, -4.47696112e-02, -1.66975055e-02,\n",
       "       -7.09498152e-02,  5.04255481e-02,  1.87541947e-01,  1.45399809e-01,\n",
       "       -3.82995680e-02, -1.00350603e-02,  5.70275150e-02,  1.24970928e-01,\n",
       "       -6.81231916e-03, -2.18557697e-02,  1.53348789e-01,  3.98756638e-02,\n",
       "       -1.13021275e-02,  5.52387871e-02, -8.45023468e-02,  6.72682524e-02,\n",
       "        9.91298705e-02,  3.27962562e-02,  3.02824583e-02, -1.43759489e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we can explore the word vector by calling the wv attribute (word vector) on the model\n",
    "w2v_model.wv['king']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('were', 0.9993231892585754),\n",
       " ('dont', 0.9993202090263367),\n",
       " ('answer', 0.9993064403533936),\n",
       " ('receive', 0.9992914199829102),\n",
       " ('get', 0.9992875456809998),\n",
       " ('gud', 0.9992870092391968),\n",
       " ('who', 0.9992806911468506),\n",
       " ('try', 0.9992780089378357),\n",
       " ('my', 0.9992777109146118),\n",
       " ('we', 0.9992774724960327)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar('king')\n",
    "\n",
    "### the results were not good because the dataset is smaller ###\n",
    "# in order to use word embeddings, we need to understand the problem in hand a little bit better\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you',\n",
       " 'to',\n",
       " 'the',\n",
       " 'and',\n",
       " 'in',\n",
       " 'is',\n",
       " 'me',\n",
       " 'my',\n",
       " 'it',\n",
       " 'for',\n",
       " 'your',\n",
       " 'call',\n",
       " 'of',\n",
       " 'that',\n",
       " 'have',\n",
       " 'on',\n",
       " 'are',\n",
       " 'now',\n",
       " 'can',\n",
       " 'so',\n",
       " 'but',\n",
       " 'not',\n",
       " 'do',\n",
       " 'or',\n",
       " 'we',\n",
       " 'will',\n",
       " 'if',\n",
       " 'get',\n",
       " 'at',\n",
       " 'be',\n",
       " 'just',\n",
       " 'no',\n",
       " 'ur',\n",
       " 'with',\n",
       " 'this',\n",
       " 'up',\n",
       " 'how',\n",
       " 'what',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'when',\n",
       " 'ok',\n",
       " 'from',\n",
       " 'free',\n",
       " 'all',\n",
       " 'out',\n",
       " 'go',\n",
       " 'll',\n",
       " 'know',\n",
       " 'day',\n",
       " 'good',\n",
       " 'like',\n",
       " 'then',\n",
       " 'come',\n",
       " 'got',\n",
       " 'am',\n",
       " 'there',\n",
       " 'its',\n",
       " 'time',\n",
       " 'he',\n",
       " 'was',\n",
       " 'love',\n",
       " 'only',\n",
       " 'want',\n",
       " 'send',\n",
       " 'as',\n",
       " 'txt',\n",
       " 'text',\n",
       " 'one',\n",
       " 'need',\n",
       " 'by',\n",
       " 'going',\n",
       " 'she',\n",
       " 'don',\n",
       " 'about',\n",
       " 'back',\n",
       " 'lor',\n",
       " 'today',\n",
       " 'stop',\n",
       " 'da',\n",
       " 'home',\n",
       " 'sorry',\n",
       " 'see',\n",
       " 'hi',\n",
       " 'still',\n",
       " 'tell',\n",
       " 'our',\n",
       " 'dont',\n",
       " 'reply',\n",
       " 'mobile',\n",
       " 'take',\n",
       " 'later',\n",
       " 'been',\n",
       " 'any',\n",
       " 'pls',\n",
       " 'did',\n",
       " 'think',\n",
       " 'please',\n",
       " 'new',\n",
       " 'some',\n",
       " 'week',\n",
       " 'her',\n",
       " 'they',\n",
       " 'phone',\n",
       " 'dear',\n",
       " 'here',\n",
       " 'where',\n",
       " 'night',\n",
       " 'oh',\n",
       " 're',\n",
       " 'well',\n",
       " 'hope',\n",
       " 'who',\n",
       " 'has',\n",
       " 'much',\n",
       " 'hey',\n",
       " 'more',\n",
       " 'claim',\n",
       " 'happy',\n",
       " 'great',\n",
       " 'give',\n",
       " 'msg',\n",
       " 've',\n",
       " 'him',\n",
       " 'won',\n",
       " 'had',\n",
       " 'yes',\n",
       " 'an',\n",
       " 'work',\n",
       " 'make',\n",
       " 'way',\n",
       " 'too',\n",
       " 'should',\n",
       " 'prize',\n",
       " 'www',\n",
       " 'right',\n",
       " 'message',\n",
       " 'wat',\n",
       " 'amp',\n",
       " 'already',\n",
       " 'said',\n",
       " 'tomorrow',\n",
       " 'ask',\n",
       " 'im',\n",
       " 'say',\n",
       " 'after',\n",
       " 'why',\n",
       " 'number',\n",
       " 'yeah',\n",
       " 'very',\n",
       " 'doing',\n",
       " 'cash',\n",
       " 'win',\n",
       " 'life',\n",
       " 'morning',\n",
       " 'last',\n",
       " 'babe',\n",
       " 'really',\n",
       " 'them',\n",
       " 'thanks',\n",
       " 'min',\n",
       " 'would',\n",
       " 'anything',\n",
       " 'miss',\n",
       " 'care',\n",
       " 'sure',\n",
       " 'every',\n",
       " 'lol',\n",
       " 'also',\n",
       " 'over',\n",
       " 'let',\n",
       " 'com',\n",
       " 'meet',\n",
       " 'find',\n",
       " 'urgent',\n",
       " 'keep',\n",
       " 'nokia',\n",
       " 'contact',\n",
       " 'cos',\n",
       " 'sent',\n",
       " 'cant',\n",
       " 'buy',\n",
       " 'even',\n",
       " 'someone',\n",
       " 'something',\n",
       " 'help',\n",
       " 'wait',\n",
       " 'his',\n",
       " 'gud',\n",
       " 'us',\n",
       " 'thing',\n",
       " 'pick',\n",
       " 'uk',\n",
       " 'could',\n",
       " 'first',\n",
       " 'feel',\n",
       " 'always',\n",
       " 'next',\n",
       " 'box',\n",
       " 'before',\n",
       " 'service',\n",
       " 'mins',\n",
       " 'which',\n",
       " 'soon',\n",
       " 'money',\n",
       " 'again',\n",
       " 'sleep',\n",
       " 'were',\n",
       " 'tonight',\n",
       " 'per',\n",
       " 'went',\n",
       " 'may',\n",
       " 'around',\n",
       " 'nice',\n",
       " 'ya',\n",
       " 'chat',\n",
       " 'sms',\n",
       " 'many',\n",
       " 'haha',\n",
       " 'coming',\n",
       " 'late',\n",
       " 'other',\n",
       " 'gonna',\n",
       " 'dun',\n",
       " 'place',\n",
       " 'told',\n",
       " 'wan',\n",
       " 'things',\n",
       " 'yet',\n",
       " 'special',\n",
       " 'year',\n",
       " 'down',\n",
       " 'fine',\n",
       " 'customer',\n",
       " 'st',\n",
       " 'friends',\n",
       " 'tone',\n",
       " 'best',\n",
       " 'friend',\n",
       " 'try',\n",
       " 'leave',\n",
       " 'guaranteed',\n",
       " 'ppm',\n",
       " 'waiting',\n",
       " 'pm',\n",
       " 'off',\n",
       " 'name',\n",
       " 'wish',\n",
       " 'smile',\n",
       " 'same',\n",
       " 'draw',\n",
       " 'didn',\n",
       " 'getting',\n",
       " 'god',\n",
       " 'heart',\n",
       " 'people',\n",
       " 'holiday',\n",
       " 'pobox',\n",
       " 'co',\n",
       " 'hello',\n",
       " 'th',\n",
       " 'use',\n",
       " 'live',\n",
       " 'done',\n",
       " 'never',\n",
       " 'stuff',\n",
       " 'days',\n",
       " 'cs',\n",
       " 'man',\n",
       " 'long',\n",
       " 'having',\n",
       " 'lunch',\n",
       " 'mind',\n",
       " 'trying',\n",
       " 'being',\n",
       " 'few',\n",
       " 'bit',\n",
       " 'receive',\n",
       " 'line',\n",
       " 'cost',\n",
       " 'than',\n",
       " 'house',\n",
       " 'thk',\n",
       " 'person',\n",
       " 'half',\n",
       " 'shit',\n",
       " 'job',\n",
       " 'better',\n",
       " 'lot',\n",
       " 'ill',\n",
       " 'class',\n",
       " 'yo',\n",
       " 'chance',\n",
       " 'finish',\n",
       " 'dat',\n",
       " 'thought',\n",
       " 'thats',\n",
       " 'play',\n",
       " 'talk',\n",
       " 'guys',\n",
       " 'world',\n",
       " 'ready',\n",
       " 'latest',\n",
       " 'car',\n",
       " 'cool',\n",
       " 'awarded',\n",
       " 'month',\n",
       " 'because',\n",
       " 'po',\n",
       " 'might',\n",
       " 'nothing',\n",
       " 'bt',\n",
       " 'check',\n",
       " 'account',\n",
       " 'meeting',\n",
       " 'girl',\n",
       " 'liao',\n",
       " 'guess',\n",
       " 'birthday',\n",
       " 'end',\n",
       " 'shows',\n",
       " 'award',\n",
       " 'problem',\n",
       " 'enjoy',\n",
       " 'big',\n",
       " 'boy',\n",
       " 'bad',\n",
       " 'into',\n",
       " 'wk',\n",
       " 'eat',\n",
       " 'forgot',\n",
       " 'start',\n",
       " 'yup',\n",
       " 'nite',\n",
       " 'nd',\n",
       " 'real',\n",
       " 'maybe',\n",
       " 'hrs',\n",
       " 'camera',\n",
       " 'weekend',\n",
       " 'calls',\n",
       " 'office',\n",
       " 'luv',\n",
       " 'shall',\n",
       " 'room',\n",
       " 'another',\n",
       " 'ah',\n",
       " 'plan',\n",
       " 'made',\n",
       " 'left',\n",
       " 'sat',\n",
       " 'watching',\n",
       " 'called',\n",
       " 'shopping',\n",
       " 'word',\n",
       " 'tv',\n",
       " 'actually',\n",
       " 'sir',\n",
       " 'rate',\n",
       " 'ever',\n",
       " 'easy',\n",
       " 'xx',\n",
       " 'xxx',\n",
       " 'thanx',\n",
       " 'tones',\n",
       " 'baby',\n",
       " 'early',\n",
       " 'dad',\n",
       " 'code',\n",
       " 'does',\n",
       " 'sweet',\n",
       " 'bed',\n",
       " 'quite',\n",
       " 'landline',\n",
       " 'reach',\n",
       " 'those',\n",
       " 'pay',\n",
       " 'wanna',\n",
       " 'once',\n",
       " 'selected',\n",
       " 'aight',\n",
       " 'remember',\n",
       " 'missing',\n",
       " 'fuck',\n",
       " 'wont',\n",
       " 'entry',\n",
       " 'offer',\n",
       " 'since',\n",
       " 'bus',\n",
       " 'minutes',\n",
       " 'fun',\n",
       " 'without',\n",
       " 'everything',\n",
       " 'lar',\n",
       " 'jus',\n",
       " 'part',\n",
       " 'dinner',\n",
       " 'leh',\n",
       " 'years',\n",
       " 'apply',\n",
       " 'video',\n",
       " 'speak',\n",
       " 'dunno',\n",
       " 'guy',\n",
       " 'hear',\n",
       " 'gift',\n",
       " 'age',\n",
       " 'working',\n",
       " 'hav',\n",
       " 'thank',\n",
       " 'probably',\n",
       " 'xmas',\n",
       " 'orange',\n",
       " 'two',\n",
       " 'anyway',\n",
       " 'den',\n",
       " 'look',\n",
       " 'says',\n",
       " 'pa',\n",
       " 'times',\n",
       " 'looking',\n",
       " 'put',\n",
       " 'goes',\n",
       " 'join',\n",
       " 'wake',\n",
       " 'didnt',\n",
       " 'til',\n",
       " 'dis',\n",
       " 'wife',\n",
       " 'most',\n",
       " 'hour',\n",
       " 'details',\n",
       " 'valid',\n",
       " 'kiss',\n",
       " 'enough',\n",
       " 'means',\n",
       " 'wanted',\n",
       " 'asked',\n",
       " 'watch',\n",
       " 'between',\n",
       " 'evening',\n",
       " 'collect',\n",
       " 'sexy',\n",
       " 'bored',\n",
       " 'town',\n",
       " 'princess',\n",
       " 'okay',\n",
       " 'todays',\n",
       " 'little',\n",
       " 'weekly',\n",
       " 'collection',\n",
       " 'dude',\n",
       " 'tmr',\n",
       " 'mail',\n",
       " 'else',\n",
       " 'must',\n",
       " 'music',\n",
       " 'while',\n",
       " 'texts',\n",
       " 'though',\n",
       " 'ringtone',\n",
       " 'until',\n",
       " 'plz',\n",
       " 'decimal',\n",
       " 'came',\n",
       " 'afternoon',\n",
       " 'missed',\n",
       " 'network',\n",
       " 'vouchers',\n",
       " 'answer',\n",
       " 'run',\n",
       " 'driving',\n",
       " 'away',\n",
       " 'till',\n",
       " 'family',\n",
       " 'dreams',\n",
       " 'address',\n",
       " 'comes',\n",
       " 'school',\n",
       " 'national',\n",
       " 'bring',\n",
       " 'date',\n",
       " 'yours',\n",
       " 'awesome',\n",
       " 'de',\n",
       " 'attempt',\n",
       " 'price',\n",
       " 'delivery',\n",
       " 'mob',\n",
       " 'alright',\n",
       " 'pain',\n",
       " 'change',\n",
       " 'messages',\n",
       " 'stay',\n",
       " 'juz',\n",
       " 'able',\n",
       " 'makes',\n",
       " 'true',\n",
       " 'net',\n",
       " 'bonus',\n",
       " 'feeling',\n",
       " 'shop',\n",
       " 'optout',\n",
       " 'tried',\n",
       " 'haven',\n",
       " 'test',\n",
       " 'friendship',\n",
       " 'abt',\n",
       " 'believe',\n",
       " 'oso',\n",
       " 'sae',\n",
       " 'words',\n",
       " 'yourself',\n",
       " 'wif',\n",
       " 'hot',\n",
       " 'congrats',\n",
       " 'rite',\n",
       " 'wid',\n",
       " 'top',\n",
       " 'happen',\n",
       " 'ring',\n",
       " 'wen',\n",
       " 'together',\n",
       " 'important',\n",
       " 'making',\n",
       " 'hurt',\n",
       " 'hair',\n",
       " 'okie',\n",
       " 'gr',\n",
       " 'havent',\n",
       " 'sch',\n",
       " 'online',\n",
       " 'old',\n",
       " 'goin',\n",
       " 'update',\n",
       " 'await',\n",
       " 'saw',\n",
       " 'minute',\n",
       " 'huh',\n",
       " 'coz',\n",
       " 'worry',\n",
       " 'mine',\n",
       " 'busy',\n",
       " 'question',\n",
       " 'either',\n",
       " 'ard',\n",
       " 'anyone',\n",
       " 'second',\n",
       " 'yesterday',\n",
       " 'land',\n",
       " 'both',\n",
       " 'mean',\n",
       " 'wil',\n",
       " 'club',\n",
       " 'double',\n",
       " 'wot',\n",
       " 'saying',\n",
       " 'these',\n",
       " 'final',\n",
       " 'hard',\n",
       " 'mths',\n",
       " 'colour',\n",
       " 'lei',\n",
       " 'unsubscribe',\n",
       " 'brother',\n",
       " 'http',\n",
       " 'email',\n",
       " 'post',\n",
       " 'hours',\n",
       " 'story',\n",
       " 'gd',\n",
       " 'calling',\n",
       " 'leaving',\n",
       " 'angry',\n",
       " 'food',\n",
       " 'break',\n",
       " 'sad',\n",
       " 'charge',\n",
       " 'beautiful',\n",
       " 'lose',\n",
       " 'close',\n",
       " 'chikku',\n",
       " 'rs',\n",
       " 'full',\n",
       " 'forget',\n",
       " 'wants',\n",
       " 'available',\n",
       " 'doesn',\n",
       " 'mom',\n",
       " 'treat',\n",
       " 'auction',\n",
       " 'took',\n",
       " 'hows',\n",
       " 'info',\n",
       " 'points',\n",
       " 'pic',\n",
       " 'plus',\n",
       " 'drop',\n",
       " 'mum',\n",
       " 'everyone',\n",
       " 'tomo',\n",
       " 'set',\n",
       " 'lucky',\n",
       " 'aft',\n",
       " 'tot',\n",
       " 'search',\n",
       " 'head',\n",
       " 'noe',\n",
       " 'drive',\n",
       " 'lots',\n",
       " 'nt',\n",
       " 'eve',\n",
       " 'game',\n",
       " 'takes',\n",
       " 'choose',\n",
       " 'found',\n",
       " 'fast',\n",
       " 'party',\n",
       " 'type',\n",
       " 'dating',\n",
       " 'news',\n",
       " 'movie',\n",
       " 'sleeping',\n",
       " 'drink',\n",
       " 'poly',\n",
       " 'each',\n",
       " 'needs',\n",
       " 'carlos',\n",
       " 'pics',\n",
       " 'haf',\n",
       " 'private',\n",
       " 'card',\n",
       " 'id',\n",
       " 'order',\n",
       " 'far',\n",
       " 'book',\n",
       " 'finished',\n",
       " 'pub',\n",
       " 'cause',\n",
       " 'happened',\n",
       " 'alone',\n",
       " 'sis',\n",
       " 'gbp',\n",
       " 'wonderful',\n",
       " 'company',\n",
       " 'sounds',\n",
       " 'row',\n",
       " 'hand',\n",
       " 'decided',\n",
       " 'goodmorning',\n",
       " 'show',\n",
       " 'lets',\n",
       " 'suite',\n",
       " 'hl',\n",
       " 'started',\n",
       " 'thinking',\n",
       " 'fri',\n",
       " 'savamob',\n",
       " 'darlin',\n",
       " 'light',\n",
       " 'face',\n",
       " 'project',\n",
       " 'smiling',\n",
       " 'ha',\n",
       " 'sun',\n",
       " 'lesson',\n",
       " 'voucher',\n",
       " 'fucking',\n",
       " 'unlimited',\n",
       " 'statement',\n",
       " 'fone',\n",
       " 'expires',\n",
       " 'congratulations',\n",
       " 'quiz',\n",
       " 'saturday',\n",
       " 'earlier',\n",
       " 'knew',\n",
       " 'content',\n",
       " 'ni',\n",
       " 'games',\n",
       " 'ten',\n",
       " 'worth',\n",
       " 'loving',\n",
       " 'used',\n",
       " 'frnds',\n",
       " 'touch',\n",
       " 'credit',\n",
       " 'prob',\n",
       " 'msgs',\n",
       " 'blue',\n",
       " 'pounds',\n",
       " 'jay',\n",
       " 'simple',\n",
       " 'welcome',\n",
       " 'smoke',\n",
       " 'wit',\n",
       " 'opt',\n",
       " 'tho',\n",
       " 'anytime',\n",
       " 'knw',\n",
       " 'lovely',\n",
       " 'enter',\n",
       " 'least',\n",
       " 'sister',\n",
       " 'identifier',\n",
       " 'side',\n",
       " 'mates',\n",
       " 'gone',\n",
       " 'lost',\n",
       " 'pretty',\n",
       " 'whats',\n",
       " 'wkly',\n",
       " 'march',\n",
       " 'finally',\n",
       " 'frm',\n",
       " 'hmmm',\n",
       " 'area',\n",
       " 'seeing',\n",
       " 'taking',\n",
       " 'chennai',\n",
       " 'fancy',\n",
       " 'trip',\n",
       " 'luck',\n",
       " 'download',\n",
       " 'cum',\n",
       " 'services',\n",
       " 'visit',\n",
       " 'wq',\n",
       " 'wasn',\n",
       " 'parents',\n",
       " 'etc',\n",
       " 'college',\n",
       " 'whatever',\n",
       " 'na',\n",
       " 'eh',\n",
       " 'point',\n",
       " 'oredi',\n",
       " 'read',\n",
       " 'yar',\n",
       " 'hold',\n",
       " 'whole',\n",
       " 'stupid',\n",
       " 'log',\n",
       " 'friday',\n",
       " 'camcorder',\n",
       " 'mrng',\n",
       " 'mu',\n",
       " 'listen',\n",
       " 'telling',\n",
       " 'mobileupd',\n",
       " 'course',\n",
       " 'india',\n",
       " 'father',\n",
       " 'john',\n",
       " 'numbers',\n",
       " 'secret',\n",
       " 'kind',\n",
       " 'invited',\n",
       " 'open',\n",
       " 'mobiles',\n",
       " 'weeks',\n",
       " 'information',\n",
       " 'discount',\n",
       " 'mate',\n",
       " 'hmv',\n",
       " 'balance',\n",
       " 'nyt',\n",
       " 'mayb',\n",
       " 'within',\n",
       " 'sex',\n",
       " 'operator',\n",
       " 'happiness',\n",
       " 'winner',\n",
       " 'reading',\n",
       " 'valued',\n",
       " 'girls',\n",
       " 'bout',\n",
       " 'lands',\n",
       " 'blood',\n",
       " 'gn',\n",
       " 'ass',\n",
       " 'offers',\n",
       " 'hit',\n",
       " 'hee',\n",
       " 'monday',\n",
       " 'grins',\n",
       " 'reason',\n",
       " 'computer',\n",
       " 'tc',\n",
       " 'tel',\n",
       " 'ltd',\n",
       " 'seen',\n",
       " 'meant',\n",
       " 'caller',\n",
       " 'outside',\n",
       " 'isn',\n",
       " 'gas',\n",
       " 'bslvyl',\n",
       " 'crazy',\n",
       " 'surprise',\n",
       " 'motorola',\n",
       " 'player',\n",
       " 'ans',\n",
       " 'yr',\n",
       " 'felt',\n",
       " 'walk',\n",
       " 'dnt',\n",
       " 'sunday',\n",
       " 'hmm',\n",
       " 'match',\n",
       " 'rates',\n",
       " 'crave',\n",
       " 'thinks',\n",
       " 'asking',\n",
       " 'comp',\n",
       " 'max',\n",
       " 'un',\n",
       " 'direct',\n",
       " 'met',\n",
       " 'ish',\n",
       " 'askd',\n",
       " 'wow',\n",
       " 'rd',\n",
       " 'almost',\n",
       " 'pass',\n",
       " 'extra',\n",
       " 'through',\n",
       " 'currently',\n",
       " 'tired',\n",
       " 'smth',\n",
       " 'nope',\n",
       " 'asap',\n",
       " 'semester',\n",
       " 'entered',\n",
       " 'usf',\n",
       " 'king',\n",
       " 'christmas',\n",
       " 'txts',\n",
       " 'sub',\n",
       " 'laptop',\n",
       " 'ipod',\n",
       " 'clean',\n",
       " 'ge',\n",
       " 'mr',\n",
       " 'sell',\n",
       " 'otherwise',\n",
       " 'case',\n",
       " 'picking',\n",
       " 'empty',\n",
       " 'ends',\n",
       " 'support',\n",
       " 'heard',\n",
       " 'ago',\n",
       " 'store',\n",
       " 'hw',\n",
       " 'gotta',\n",
       " 'press',\n",
       " 'bcoz',\n",
       " 'wc',\n",
       " 'reached',\n",
       " 'joy',\n",
       " 'uncle',\n",
       " 'park',\n",
       " 'ending',\n",
       " 'studying',\n",
       " 'boytoy',\n",
       " 'checking',\n",
       " 'reveal',\n",
       " 'rental',\n",
       " 'months',\n",
       " 'water',\n",
       " 'forever',\n",
       " 'del',\n",
       " 'nah',\n",
       " 'mo',\n",
       " 'cup',\n",
       " 'redeemed',\n",
       " 'convey',\n",
       " 'via',\n",
       " 'getzed',\n",
       " 'understand',\n",
       " 'sofa',\n",
       " 'bath',\n",
       " 'gal',\n",
       " 'fact',\n",
       " 'neva',\n",
       " 'somewhere',\n",
       " 'dream',\n",
       " 'difficult',\n",
       " 'swing',\n",
       " 'pete',\n",
       " 'ip',\n",
       " 'ts',\n",
       " 'especially',\n",
       " 'yrs',\n",
       " 'slowly',\n",
       " 'mm',\n",
       " 'questions',\n",
       " 'boss',\n",
       " 'eg',\n",
       " 'mon',\n",
       " 'orchard',\n",
       " 'none',\n",
       " 'die',\n",
       " 'snow',\n",
       " 'std',\n",
       " 'red',\n",
       " 'ntt',\n",
       " 'somebody',\n",
       " 'ex',\n",
       " 'abiola',\n",
       " 'leaves',\n",
       " 'pound',\n",
       " 'comin',\n",
       " 'self',\n",
       " 'booked',\n",
       " 'wishing',\n",
       " 'loved',\n",
       " 'energy',\n",
       " 'woke',\n",
       " 'sending',\n",
       " 'kate',\n",
       " 'talking',\n",
       " 'wap',\n",
       " 'doin',\n",
       " 'their',\n",
       " 'poor',\n",
       " 'comuk',\n",
       " 'shower',\n",
       " 'correct',\n",
       " 'exam',\n",
       " 'worried',\n",
       " 'slow',\n",
       " 'confirm',\n",
       " 'deal',\n",
       " 'freemsg',\n",
       " 'hospital',\n",
       " 'ac',\n",
       " 'lazy',\n",
       " 'phones',\n",
       " 'mode',\n",
       " 'al',\n",
       " 'silent',\n",
       " 'sk',\n",
       " 'reward',\n",
       " 'replying',\n",
       " 'la',\n",
       " 'warm',\n",
       " 'yep',\n",
       " 'small',\n",
       " 'coffee',\n",
       " 'bb',\n",
       " 'joined',\n",
       " 'itself',\n",
       " 'rakhesh',\n",
       " 'future',\n",
       " 'weight',\n",
       " 'thru',\n",
       " 'immediately',\n",
       " 'cd',\n",
       " 'sort',\n",
       " 'near',\n",
       " 'street',\n",
       " 'sound',\n",
       " 'goto',\n",
       " 'doctor',\n",
       " 'ldew',\n",
       " 'link',\n",
       " 'ho',\n",
       " 'save',\n",
       " 'possible',\n",
       " 'representative',\n",
       " 'sea',\n",
       " 'plans',\n",
       " 'safe',\n",
       " 'tampa',\n",
       " 'during',\n",
       " 'bx',\n",
       " 'doesnt',\n",
       " 'south',\n",
       " 'din',\n",
       " 'fantastic',\n",
       " 'gets',\n",
       " 'custcare',\n",
       " 'txting',\n",
       " 'complimentary',\n",
       " 'goodnight',\n",
       " 'ldn',\n",
       " 'kids',\n",
       " 'colleagues',\n",
       " 'miracle',\n",
       " 'deep',\n",
       " 'member',\n",
       " 'wrong',\n",
       " 'merry',\n",
       " 'truth',\n",
       " 'police',\n",
       " 'sunshine',\n",
       " 'cr',\n",
       " 'specially',\n",
       " ...]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking all of the words that our model has created (\"learned\") a vector for\n",
    "w2v_model.wv.index2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-6ae7b9a301f0>:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  w2v_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in w2v_model.wv.index2word]) for ls in X_test])\n"
     ]
    }
   ],
   "source": [
    "### generate aggregated sentence vectors based on the word vectors for each word in the sentence\n",
    "# we loop through each text message (ls) within the test set\n",
    "# next we iterate through each word (represented by 'i') in that text message\n",
    "# each word is called into wv attribute of the model \n",
    "    # ---> to get its word vector\n",
    "# the only condition is that we try to return the vector AS LONG AS it was RETURNED BY THE MODEL (if i in w2v_model.wv.index2word)\n",
    "# the returned list (from the nested list comprehension statement) is wraped into an array (1D)\n",
    "    # that array is wrapped again in an outside array\n",
    "    # ---> a nested set of arrays within an array\n",
    "    \n",
    "w2v_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in w2v_model.wv.index2word]) for ls in X_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "1\n",
      "1115\n",
      "[array([[-0.00123451,  0.01461569,  0.01020308, ...,  0.01940734,\n",
      "         0.01816209, -0.06401429],\n",
      "       [-0.05081618,  0.24623837,  0.07502738, ...,  0.21390168,\n",
      "         0.1759904 , -0.8384252 ],\n",
      "       [-0.06182301,  0.25474226,  0.07726886, ...,  0.21941733,\n",
      "         0.18692842, -0.88128257],\n",
      "       ...,\n",
      "       [-0.06097978,  0.2838241 ,  0.07886321, ...,  0.24613678,\n",
      "         0.20931083, -0.9697612 ],\n",
      "       [-0.06732642,  0.26313898,  0.07885629, ...,  0.23650844,\n",
      "         0.20482902, -0.9468216 ],\n",
      "       [-0.00241862,  0.03177935,  0.00645023, ...,  0.02196146,\n",
      "         0.02108919, -0.1051791 ]], dtype=float32)\n",
      " array([[-4.37482074e-02,  1.82962731e-01,  5.07822633e-02,\n",
      "        -6.22133426e-02, -4.64364141e-01, -9.17480364e-02,\n",
      "         6.02119714e-02, -6.58415109e-02, -4.34282899e-01,\n",
      "        -8.30904096e-02,  2.08749160e-01,  2.36286834e-01,\n",
      "        -9.13146585e-02,  2.33189702e-01, -5.68525754e-02,\n",
      "        -2.77045429e-01, -3.67519468e-01, -3.48297097e-02,\n",
      "        -3.16627562e-01,  5.33116646e-02, -4.11196470e-01,\n",
      "        -2.23318394e-02,  1.85837477e-01, -1.03955604e-01,\n",
      "         2.29632165e-02, -4.15222734e-01,  2.16740564e-01,\n",
      "        -1.00288153e-01, -4.44040820e-02,  2.35316783e-01,\n",
      "         3.04478765e-01, -5.82189083e-01, -2.27988303e-01,\n",
      "         2.93162286e-01, -1.86131030e-01,  2.38946572e-01,\n",
      "         4.74811703e-01,  1.94593906e-01, -1.37823269e-01,\n",
      "        -1.41030969e-02,  1.15305088e-01,  7.92226568e-02,\n",
      "         4.33469228e-02, -8.98904204e-02,  2.11342294e-02,\n",
      "         2.70649821e-01, -1.17801413e-01, -4.97759581e-01,\n",
      "         1.55032471e-01, -7.62645900e-03, -6.79191649e-02,\n",
      "         1.84845477e-01, -1.33816913e-01, -5.10457516e-01,\n",
      "        -6.54564083e-01, -3.27547669e-01,  1.81329548e-02,\n",
      "         1.10689700e-01, -4.68818277e-01,  4.31809932e-01,\n",
      "        -1.50120899e-01, -9.68679134e-03,  1.05286822e-01,\n",
      "         1.79006439e-02,  2.34435365e-01, -3.73736657e-02,\n",
      "        -6.06354833e-01, -2.02689618e-01,  5.73908448e-01,\n",
      "        -1.18287094e-01, -5.95795035e-01, -1.22507006e-01,\n",
      "        -5.54763019e-01,  6.08453333e-01,  4.44725044e-02,\n",
      "         3.48482728e-01,  1.90654099e-01, -1.67984799e-01,\n",
      "        -2.07902044e-01, -6.80882931e-02, -3.04435015e-01,\n",
      "         2.02780992e-01,  7.94844091e-01,  6.12689793e-01,\n",
      "        -1.80417508e-01, -5.16170487e-02,  2.42009357e-01,\n",
      "         5.16851008e-01, -2.41596047e-02, -1.12137333e-01,\n",
      "         6.42742217e-01,  1.70711920e-01, -5.10827303e-02,\n",
      "         2.42945656e-01, -3.53609562e-01,  2.69871086e-01,\n",
      "         4.12254542e-01,  1.54089436e-01,  1.29505977e-01,\n",
      "        -6.29214466e-01],\n",
      "       [-3.58166452e-03,  2.16902848e-02,  3.31402593e-03,\n",
      "        -1.05931675e-02, -4.54745740e-02, -1.15374662e-02,\n",
      "         3.59543390e-03, -7.18928734e-03, -4.06867489e-02,\n",
      "        -1.20352888e-02,  2.33715344e-02,  1.86326616e-02,\n",
      "        -7.01201661e-03,  1.80498231e-02, -5.80587098e-03,\n",
      "        -2.43843663e-02, -3.86040844e-02, -5.03818830e-03,\n",
      "        -2.98201367e-02,  3.61911790e-03, -4.21766341e-02,\n",
      "        -1.23444782e-03,  2.08623558e-02, -1.33257424e-02,\n",
      "        -2.27186899e-03, -3.54927890e-02,  1.87198929e-02,\n",
      "        -1.00157652e-02,  6.78208889e-05,  2.08327603e-02,\n",
      "         2.92136353e-02, -5.79644926e-02, -1.76521167e-02,\n",
      "         2.68485826e-02, -1.59578808e-02,  2.44176555e-02,\n",
      "         4.59272861e-02,  1.46879666e-02, -1.38537185e-02,\n",
      "        -1.47875038e-03,  1.33510903e-02,  1.03306267e-02,\n",
      "         1.29446457e-03, -7.30896648e-03, -2.36859289e-03,\n",
      "         2.46009864e-02, -8.07043631e-03, -5.02589680e-02,\n",
      "         1.62372850e-02,  3.41380271e-03, -8.86419043e-03,\n",
      "         2.03416683e-02, -1.41155459e-02, -5.00673205e-02,\n",
      "        -6.17356822e-02, -3.05851549e-02, -4.66811209e-04,\n",
      "         1.03208544e-02, -4.20684777e-02,  4.49155867e-02,\n",
      "        -1.63066909e-02, -2.72082194e-04,  5.48330508e-03,\n",
      "        -8.84342822e-04,  2.42754556e-02, -7.91685283e-03,\n",
      "        -5.66441640e-02, -2.00350657e-02,  4.95834462e-02,\n",
      "        -1.18501671e-02, -5.51776551e-02, -8.48240312e-03,\n",
      "        -5.29991016e-02,  5.76508865e-02,  2.60583754e-03,\n",
      "         3.15913670e-02,  1.44345555e-02, -1.41008776e-02,\n",
      "        -2.02634204e-02, -8.74282978e-03, -2.54862569e-02,\n",
      "         2.33755503e-02,  7.51220733e-02,  5.39388210e-02,\n",
      "        -2.06470750e-02, -3.29367095e-03,  1.93290152e-02,\n",
      "         5.06205074e-02, -2.82140961e-03, -9.81676485e-03,\n",
      "         5.59151806e-02,  1.68412905e-02, -2.49420968e-03,\n",
      "         2.41144616e-02, -3.29782143e-02,  2.78534386e-02,\n",
      "         3.98648418e-02,  1.73406303e-02,  7.97579437e-03,\n",
      "        -5.49488552e-02],\n",
      "       [-6.46070093e-02,  2.67564774e-01,  7.66083896e-02,\n",
      "        -8.75188857e-02, -6.92245960e-01, -1.28063500e-01,\n",
      "         8.36848244e-02, -9.61509198e-02, -6.40210986e-01,\n",
      "        -1.17599763e-01,  3.12781245e-01,  3.48031342e-01,\n",
      "        -1.33223787e-01,  3.40780705e-01, -8.51039514e-02,\n",
      "        -3.95150602e-01, -5.33109486e-01, -4.05898467e-02,\n",
      "        -4.72624063e-01,  7.30509833e-02, -5.97769260e-01,\n",
      "        -3.05919759e-02,  2.70621538e-01, -1.52378604e-01,\n",
      "         3.17192972e-02, -6.13814890e-01,  3.11088294e-01,\n",
      "        -1.49319783e-01, -6.29952624e-02,  3.53347659e-01,\n",
      "         4.46313560e-01, -8.63859892e-01, -3.24426383e-01,\n",
      "         4.17556226e-01, -2.75049865e-01,  3.46938789e-01,\n",
      "         6.97337806e-01,  2.78876752e-01, -2.00193211e-01,\n",
      "        -3.03943437e-02,  1.70416147e-01,  1.17737025e-01,\n",
      "         6.28421903e-02, -1.25051692e-01,  3.49772461e-02,\n",
      "         3.90339911e-01, -1.71475813e-01, -7.21674919e-01,\n",
      "         2.34523863e-01, -1.54527007e-02, -1.02675654e-01,\n",
      "         2.76342124e-01, -1.92943007e-01, -7.55001962e-01,\n",
      "        -9.73085403e-01, -4.94645059e-01,  2.57479064e-02,\n",
      "         1.57256112e-01, -7.07531393e-01,  6.32871747e-01,\n",
      "        -2.08858937e-01, -1.40723223e-02,  1.56191111e-01,\n",
      "         2.76113227e-02,  3.32754612e-01, -6.53955638e-02,\n",
      "        -8.99837554e-01, -2.86068827e-01,  8.34260523e-01,\n",
      "        -1.79623798e-01, -8.71432066e-01, -1.79830194e-01,\n",
      "        -8.09789717e-01,  8.84738445e-01,  7.26341605e-02,\n",
      "         5.19995630e-01,  2.89556205e-01, -2.41526872e-01,\n",
      "        -3.02200764e-01, -9.99863744e-02, -4.45251316e-01,\n",
      "         2.99192280e-01,  1.18080842e+00,  9.04592097e-01,\n",
      "        -2.58039236e-01, -7.00791627e-02,  3.61890316e-01,\n",
      "         7.65254259e-01, -4.06666845e-02, -1.60580620e-01,\n",
      "         9.52955723e-01,  2.42275313e-01, -6.53381050e-02,\n",
      "         3.60532254e-01, -5.21463215e-01,  3.89763296e-01,\n",
      "         6.12536490e-01,  2.22347125e-01,  1.99136585e-01,\n",
      "        -9.24806416e-01],\n",
      "       [-5.37059829e-02,  2.45690599e-01,  7.28337020e-02,\n",
      "        -8.27448294e-02, -6.32888675e-01, -1.28516018e-01,\n",
      "         7.94748738e-02, -9.28683728e-02, -5.88893712e-01,\n",
      "        -1.13748401e-01,  2.81575292e-01,  3.10299784e-01,\n",
      "        -1.15569882e-01,  3.21176112e-01, -6.97337687e-02,\n",
      "        -3.62477601e-01, -4.94282097e-01, -4.00703847e-02,\n",
      "        -4.31865901e-01,  7.14214891e-02, -5.49896419e-01,\n",
      "        -2.42730882e-02,  2.53350496e-01, -1.38421491e-01,\n",
      "         3.24941240e-02, -5.64310133e-01,  2.88959056e-01,\n",
      "        -1.27517194e-01, -6.47668317e-02,  3.24052095e-01,\n",
      "         4.03807670e-01, -7.89094150e-01, -3.02275389e-01,\n",
      "         3.89197230e-01, -2.56724387e-01,  3.18557531e-01,\n",
      "         6.29092515e-01,  2.64042050e-01, -1.84951216e-01,\n",
      "        -2.78147701e-02,  1.64359659e-01,  1.05006486e-01,\n",
      "         5.82223609e-02, -1.12829819e-01,  3.97536829e-02,\n",
      "         3.56581450e-01, -1.53085262e-01, -6.69504166e-01,\n",
      "         2.17679128e-01, -8.51371512e-03, -9.12251249e-02,\n",
      "         2.52323925e-01, -1.81974739e-01, -6.93110824e-01,\n",
      "        -8.89619112e-01, -4.44133222e-01,  1.54612670e-02,\n",
      "         1.37609497e-01, -6.35353625e-01,  5.83733678e-01,\n",
      "        -1.91084504e-01, -9.71165858e-03,  1.38115317e-01,\n",
      "         2.35870555e-02,  3.13535422e-01, -5.45047298e-02,\n",
      "        -8.22158933e-01, -2.59348184e-01,  7.64358461e-01,\n",
      "        -1.56766862e-01, -7.96858966e-01, -1.68784082e-01,\n",
      "        -7.43255079e-01,  8.04858208e-01,  6.95521384e-02,\n",
      "         4.76314515e-01,  2.69382536e-01, -2.18979731e-01,\n",
      "        -2.79802769e-01, -8.75237733e-02, -4.15831029e-01,\n",
      "         2.72704363e-01,  1.07838011e+00,  8.24105799e-01,\n",
      "        -2.46157214e-01, -6.05232045e-02,  3.18042964e-01,\n",
      "         7.09244728e-01, -3.77896018e-02, -1.43470705e-01,\n",
      "         8.64903927e-01,  2.20700875e-01, -5.88370450e-02,\n",
      "         3.27183157e-01, -4.85253602e-01,  3.59225273e-01,\n",
      "         5.56748986e-01,  2.08516911e-01,  1.87308475e-01,\n",
      "        -8.48207593e-01]], dtype=float32)\n",
      " array([[-0.02828865,  0.13869494,  0.03883994, ...,  0.12074104,\n",
      "         0.10900266, -0.48823148],\n",
      "       [-0.03829008,  0.15205072,  0.04619513, ...,  0.12483961,\n",
      "         0.10867433, -0.5121176 ],\n",
      "       [-0.04074684,  0.16042896,  0.04042121, ...,  0.1388833 ,\n",
      "         0.11995117, -0.5666336 ],\n",
      "       ...,\n",
      "       [-0.07986353,  0.31871942,  0.09119347, ...,  0.2870373 ,\n",
      "         0.24100201, -1.1477952 ],\n",
      "       [-0.03707288,  0.13609014,  0.04387677, ...,  0.12543142,\n",
      "         0.10202479, -0.49745134],\n",
      "       [-0.05081618,  0.24623837,  0.07502738, ...,  0.21390168,\n",
      "         0.1759904 , -0.8384252 ]], dtype=float32)\n",
      " ...\n",
      " array([[-0.06617746,  0.28711134,  0.07814521, ...,  0.25524464,\n",
      "         0.2227426 , -1.0146083 ],\n",
      "       [-0.04589621,  0.23995277,  0.07314719, ...,  0.21193525,\n",
      "         0.17991331, -0.8291853 ],\n",
      "       [-0.01446062,  0.04826371,  0.01403762, ...,  0.04489115,\n",
      "         0.03594309, -0.18658158],\n",
      "       ...,\n",
      "       [-0.06688263,  0.27926558,  0.0850783 , ...,  0.24195257,\n",
      "         0.20628735, -0.99668545],\n",
      "       [-0.0189655 ,  0.06897254,  0.02164182, ...,  0.06395487,\n",
      "         0.04782353, -0.2510656 ],\n",
      "       [-0.05009377,  0.24838986,  0.07608575, ...,  0.22410782,\n",
      "         0.18275511, -0.87135315]], dtype=float32)\n",
      " array([[-0.03250399,  0.10160661,  0.02784375, ...,  0.08432878,\n",
      "         0.07393138, -0.3511795 ],\n",
      "       [-0.03250399,  0.10160661,  0.02784375, ...,  0.08432878,\n",
      "         0.07393138, -0.3511795 ],\n",
      "       [-0.06720985,  0.29128063,  0.08060677, ...,  0.24663316,\n",
      "         0.21435028, -1.0153285 ],\n",
      "       ...,\n",
      "       [-0.07704421,  0.3193256 ,  0.0961184 , ...,  0.27160078,\n",
      "         0.2297255 , -1.1356844 ],\n",
      "       [ 0.00295088,  0.00899145, -0.00252591, ...,  0.00383495,\n",
      "         0.00316113, -0.01853948],\n",
      "       [-0.04145548,  0.14721626,  0.03630459, ...,  0.1188362 ,\n",
      "         0.10603198, -0.50529975]], dtype=float32)\n",
      " array([[-7.98635259e-02,  3.18719417e-01,  9.11934674e-02,\n",
      "        -1.16658762e-01, -8.42518330e-01, -1.62038282e-01,\n",
      "         9.37893018e-02, -1.17673129e-01, -7.95785487e-01,\n",
      "        -1.39570355e-01,  3.84056151e-01,  4.11443561e-01,\n",
      "        -1.67871878e-01,  4.31742847e-01, -9.17735100e-02,\n",
      "        -4.82189655e-01, -6.63473785e-01, -5.20112626e-02,\n",
      "        -5.85813761e-01,  9.90676284e-02, -7.43207157e-01,\n",
      "        -4.73593771e-02,  3.35473835e-01, -1.97572276e-01,\n",
      "         4.14728858e-02, -7.60604978e-01,  3.85553122e-01,\n",
      "        -1.84238628e-01, -7.73211196e-02,  4.52715755e-01,\n",
      "         5.42500794e-01, -1.06616604e+00, -4.03306127e-01,\n",
      "         5.17181218e-01, -3.37110609e-01,  4.42570180e-01,\n",
      "         8.55498374e-01,  3.57433587e-01, -2.54302084e-01,\n",
      "        -3.14420387e-02,  2.17220530e-01,  1.40082672e-01,\n",
      "         7.41866902e-02, -1.53603420e-01,  5.17148487e-02,\n",
      "         4.85222280e-01, -2.13226855e-01, -8.78993452e-01,\n",
      "         2.98309922e-01, -1.16893072e-02, -1.17427289e-01,\n",
      "         3.55717450e-01, -2.36132368e-01, -9.38588798e-01,\n",
      "        -1.18165696e+00, -6.04321897e-01,  2.86836084e-02,\n",
      "         1.75042465e-01, -8.64311934e-01,  7.86992967e-01,\n",
      "        -2.44142398e-01, -7.80419819e-03,  1.86819732e-01,\n",
      "         3.05500682e-02,  4.18709904e-01, -6.91369548e-02,\n",
      "        -1.10523808e+00, -3.55059415e-01,  1.02626467e+00,\n",
      "        -2.11868405e-01, -1.07186413e+00, -2.17607871e-01,\n",
      "        -9.89116848e-01,  1.09490633e+00,  9.46370438e-02,\n",
      "         6.39990628e-01,  3.68256450e-01, -2.99694210e-01,\n",
      "        -3.70075524e-01, -1.21446401e-01, -5.53007483e-01,\n",
      "         3.63286823e-01,  1.44911265e+00,  1.11726856e+00,\n",
      "        -3.11310410e-01, -9.75443199e-02,  4.36830968e-01,\n",
      "         9.45761859e-01, -5.49403280e-02, -2.03314513e-01,\n",
      "         1.17539608e+00,  3.02023858e-01, -7.53647089e-02,\n",
      "         4.54298407e-01, -6.35699987e-01,  4.83121186e-01,\n",
      "         7.50992656e-01,  2.87037313e-01,  2.41002008e-01,\n",
      "        -1.14779520e+00],\n",
      "       [ 1.55770313e-03,  7.69182865e-04,  7.05261846e-05,\n",
      "         1.90805923e-03, -1.51475798e-03, -4.51640459e-03,\n",
      "         8.15709354e-04,  3.68077512e-04, -5.23301074e-04,\n",
      "        -5.00813778e-03,  1.23263116e-03,  2.01238366e-03,\n",
      "         2.19654269e-03,  5.43989800e-03, -2.37322855e-03,\n",
      "        -7.06933159e-03, -8.19508545e-03, -3.50456382e-03,\n",
      "        -2.01136689e-03,  2.42675235e-03, -2.44046678e-03,\n",
      "        -2.70683062e-03,  3.67365801e-03,  2.96825921e-04,\n",
      "         2.39516981e-03, -6.54320698e-04,  5.18085901e-03,\n",
      "        -4.72244486e-04, -1.52592070e-03,  2.47234828e-03,\n",
      "         3.98988696e-03, -3.51006165e-03, -3.79663252e-05,\n",
      "         4.92305355e-03,  1.58997322e-03,  2.28476292e-03,\n",
      "         5.93787106e-03, -1.64015428e-03, -4.30549588e-03,\n",
      "        -4.46135225e-03,  5.02936426e-04, -2.12791632e-03,\n",
      "        -3.29824979e-04,  4.74855362e-04, -6.93817565e-04,\n",
      "         5.07906731e-03,  3.19229090e-03, -6.42611587e-04,\n",
      "        -1.88897678e-03, -3.54151009e-03,  3.90800228e-03,\n",
      "         1.45800965e-04,  2.30749371e-03, -7.78793590e-03,\n",
      "        -8.92209355e-03, -3.99904139e-03,  9.81341349e-04,\n",
      "         5.56410290e-03, -7.67607521e-03,  7.23190897e-04,\n",
      "         4.10796565e-05, -2.15596374e-04,  5.69150259e-04,\n",
      "        -4.29303106e-03, -2.51612184e-03, -5.32975653e-04,\n",
      "        -7.93570536e-04,  2.78049707e-03,  3.51279019e-03,\n",
      "        -5.94961364e-03, -1.60658243e-03,  1.08556612e-03,\n",
      "        -9.78516880e-04,  6.61212346e-03,  5.13840280e-03,\n",
      "         3.61362169e-03, -1.37355318e-03,  2.42964295e-03,\n",
      "         1.43049983e-03, -4.06059204e-03,  1.23964448e-03,\n",
      "         4.79075825e-03,  1.22364406e-02,  1.00719575e-02,\n",
      "        -4.16741706e-03,  5.64438466e-04,  2.20662821e-03,\n",
      "         8.50244239e-03, -4.98867966e-03,  2.93786405e-03,\n",
      "         5.44952089e-03,  9.00247775e-04,  6.36296580e-04,\n",
      "         3.90630728e-03, -7.85464142e-03,  3.96907912e-04,\n",
      "         7.14898389e-03, -7.40829390e-04,  2.33559287e-03,\n",
      "        -6.64891489e-03],\n",
      "       [-1.52991023e-02,  5.85023873e-02,  1.59079209e-02,\n",
      "        -1.58908274e-02, -1.63320258e-01, -3.09499912e-02,\n",
      "         1.47675769e-02, -1.90706402e-02, -1.44331038e-01,\n",
      "        -2.45142058e-02,  6.74216077e-02,  8.34251121e-02,\n",
      "        -3.13456766e-02,  7.83725753e-02, -1.36568639e-02,\n",
      "        -8.76591131e-02, -1.23644806e-01, -1.14613306e-02,\n",
      "        -1.05766237e-01,  2.00407989e-02, -1.43972814e-01,\n",
      "        -7.49984011e-03,  5.95872365e-02, -3.53684574e-02,\n",
      "         6.97303144e-03, -1.45660713e-01,  6.88247308e-02,\n",
      "        -3.14887874e-02, -1.68229267e-02,  8.49506706e-02,\n",
      "         1.01087481e-01, -1.98649362e-01, -7.18488470e-02,\n",
      "         9.29307640e-02, -6.85345381e-02,  7.93491602e-02,\n",
      "         1.55484766e-01,  6.66014031e-02, -4.62739691e-02,\n",
      "        -8.45010486e-03,  3.82772870e-02,  2.33971346e-02,\n",
      "         1.43573480e-02, -3.16737518e-02,  9.47273802e-03,\n",
      "         9.16137248e-02, -4.13189158e-02, -1.64555401e-01,\n",
      "         5.70465177e-02,  5.79695879e-05, -2.68330500e-02,\n",
      "         6.62911907e-02, -4.66430783e-02, -1.75453514e-01,\n",
      "        -2.21692458e-01, -1.10586248e-01,  7.33440102e-04,\n",
      "         3.61782834e-02, -1.64006457e-01,  1.42187700e-01,\n",
      "        -4.69375513e-02, -2.37531378e-03,  3.30649242e-02,\n",
      "         4.89234878e-03,  8.04690495e-02, -1.46463448e-02,\n",
      "        -2.10305735e-01, -6.62669167e-02,  1.96458176e-01,\n",
      "        -4.09712158e-02, -2.00922191e-01, -4.78187129e-02,\n",
      "        -1.85717583e-01,  2.07293153e-01,  1.91426855e-02,\n",
      "         1.24265455e-01,  7.19699562e-02, -5.05497605e-02,\n",
      "        -7.00512528e-02, -1.97778959e-02, -1.09330200e-01,\n",
      "         6.80367872e-02,  2.75335878e-01,  2.07095072e-01,\n",
      "        -5.89873157e-02, -2.08813623e-02,  8.55005309e-02,\n",
      "         1.76106930e-01, -1.30293760e-02, -3.17404158e-02,\n",
      "         2.23270729e-01,  5.90684116e-02, -1.91708785e-02,\n",
      "         8.41704980e-02, -1.16130173e-01,  8.87355953e-02,\n",
      "         1.41473696e-01,  4.91117463e-02,  4.93960977e-02,\n",
      "        -2.11115867e-01]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(type(w2v_vect))\n",
    "print(w2v_vect.ndim)\n",
    "print(w2v_vect.size)\n",
    "print(w2v_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 17\n",
      "6 4\n",
      "15 14\n",
      "22 20\n",
      "7 7\n",
      "23 22\n",
      "20 19\n",
      "8 6\n",
      "8 7\n",
      "7 7\n",
      "17 16\n",
      "5 5\n",
      "10 10\n",
      "5 4\n",
      "16 16\n",
      "9 9\n",
      "9 8\n",
      "6 5\n",
      "15 14\n",
      "7 5\n",
      "2 2\n",
      "7 6\n",
      "11 9\n",
      "20 20\n",
      "18 17\n",
      "14 10\n",
      "9 9\n",
      "5 4\n",
      "4 4\n",
      "5 5\n",
      "21 18\n",
      "16 12\n",
      "20 19\n",
      "8 7\n",
      "8 8\n",
      "13 13\n",
      "13 13\n",
      "26 16\n",
      "4 4\n",
      "9 9\n",
      "20 19\n",
      "6 5\n",
      "22 22\n",
      "27 24\n",
      "5 5\n",
      "26 25\n",
      "31 31\n",
      "6 6\n",
      "24 21\n",
      "20 17\n",
      "30 24\n",
      "20 20\n",
      "11 10\n",
      "25 24\n",
      "7 5\n",
      "7 6\n",
      "5 3\n",
      "30 25\n",
      "5 3\n",
      "16 15\n",
      "10 10\n",
      "19 17\n",
      "8 6\n",
      "7 6\n",
      "9 9\n",
      "8 8\n",
      "19 17\n",
      "15 15\n",
      "25 20\n",
      "24 20\n",
      "13 10\n",
      "17 13\n",
      "13 12\n",
      "17 17\n",
      "19 19\n",
      "6 6\n",
      "12 10\n",
      "4 3\n",
      "31 31\n",
      "7 4\n",
      "22 20\n",
      "13 12\n",
      "15 14\n",
      "7 7\n",
      "5 5\n",
      "13 13\n",
      "27 22\n",
      "12 12\n",
      "5 5\n",
      "9 8\n",
      "17 17\n",
      "5 5\n",
      "5 5\n",
      "4 4\n",
      "22 22\n",
      "13 13\n",
      "5 5\n",
      "14 13\n",
      "8 7\n",
      "6 6\n",
      "8 8\n",
      "1 1\n",
      "5 5\n",
      "18 17\n",
      "13 12\n",
      "2 2\n",
      "11 7\n",
      "3 3\n",
      "5 5\n",
      "18 17\n",
      "10 10\n",
      "27 26\n",
      "7 7\n",
      "10 10\n",
      "3 3\n",
      "4 3\n",
      "20 20\n",
      "4 4\n",
      "12 8\n",
      "4 4\n",
      "1 1\n",
      "7 6\n",
      "4 3\n",
      "22 21\n",
      "29 28\n",
      "5 5\n",
      "5 5\n",
      "11 9\n",
      "46 43\n",
      "12 11\n",
      "21 19\n",
      "11 10\n",
      "1 1\n",
      "5 4\n",
      "24 22\n",
      "11 10\n",
      "4 1\n",
      "6 6\n",
      "16 13\n",
      "6 6\n",
      "3 3\n",
      "8 7\n",
      "8 7\n",
      "16 14\n",
      "25 25\n",
      "6 5\n",
      "9 7\n",
      "25 25\n",
      "22 21\n",
      "6 6\n",
      "14 13\n",
      "7 6\n",
      "19 19\n",
      "26 23\n",
      "20 19\n",
      "52 46\n",
      "5 5\n",
      "12 10\n",
      "5 5\n",
      "22 22\n",
      "6 6\n",
      "22 19\n",
      "22 22\n",
      "17 17\n",
      "22 22\n",
      "5 3\n",
      "27 26\n",
      "9 8\n",
      "11 11\n",
      "22 20\n",
      "9 8\n",
      "36 31\n",
      "6 5\n",
      "6 6\n",
      "6 5\n",
      "23 22\n",
      "15 14\n",
      "4 4\n",
      "22 15\n",
      "19 19\n",
      "24 16\n",
      "2 2\n",
      "6 5\n",
      "36 32\n",
      "25 24\n",
      "7 7\n",
      "25 23\n",
      "9 9\n",
      "7 6\n",
      "18 16\n",
      "7 5\n",
      "8 7\n",
      "5 5\n",
      "24 22\n",
      "6 6\n",
      "7 7\n",
      "4 4\n",
      "13 13\n",
      "6 6\n",
      "22 20\n",
      "30 28\n",
      "28 26\n",
      "18 17\n",
      "14 13\n",
      "39 30\n",
      "11 11\n",
      "8 8\n",
      "4 3\n",
      "11 11\n",
      "14 11\n",
      "8 8\n",
      "9 6\n",
      "15 15\n",
      "8 8\n",
      "6 4\n",
      "8 8\n",
      "6 6\n",
      "27 25\n",
      "18 17\n",
      "11 11\n",
      "21 21\n",
      "26 25\n",
      "31 29\n",
      "6 4\n",
      "54 38\n",
      "19 18\n",
      "7 7\n",
      "9 7\n",
      "5 5\n",
      "20 20\n",
      "30 30\n",
      "14 14\n",
      "18 18\n",
      "26 25\n",
      "3 3\n",
      "6 5\n",
      "31 29\n",
      "1 1\n",
      "8 8\n",
      "16 13\n",
      "16 14\n",
      "14 13\n",
      "37 31\n",
      "25 25\n",
      "5 5\n",
      "29 28\n",
      "6 3\n",
      "8 7\n",
      "25 25\n",
      "3 3\n",
      "39 36\n",
      "8 7\n",
      "6 6\n",
      "30 25\n",
      "25 23\n",
      "16 16\n",
      "6 6\n",
      "27 27\n",
      "7 7\n",
      "11 9\n",
      "5 5\n",
      "6 4\n",
      "4 4\n",
      "8 8\n",
      "6 6\n",
      "13 13\n",
      "9 8\n",
      "5 3\n",
      "11 11\n",
      "5 5\n",
      "16 15\n",
      "4 2\n",
      "18 16\n",
      "9 8\n",
      "12 10\n",
      "3 3\n",
      "5 4\n",
      "4 4\n",
      "21 21\n",
      "9 9\n",
      "23 22\n",
      "8 8\n",
      "5 5\n",
      "4 4\n",
      "21 20\n",
      "36 34\n",
      "20 18\n",
      "14 13\n",
      "9 8\n",
      "2 2\n",
      "6 6\n",
      "19 8\n",
      "26 26\n",
      "23 19\n",
      "8 7\n",
      "21 19\n",
      "17 16\n",
      "24 19\n",
      "5 5\n",
      "10 10\n",
      "25 21\n",
      "14 13\n",
      "12 12\n",
      "14 12\n",
      "27 8\n",
      "8 8\n",
      "13 13\n",
      "5 3\n",
      "14 13\n",
      "19 14\n",
      "6 6\n",
      "22 21\n",
      "8 8\n",
      "9 9\n",
      "4 4\n",
      "4 4\n",
      "30 28\n",
      "8 8\n",
      "24 23\n",
      "6 5\n",
      "30 27\n",
      "21 21\n",
      "8 6\n",
      "4 4\n",
      "23 21\n",
      "4 4\n",
      "56 51\n",
      "14 14\n",
      "22 16\n",
      "5 5\n",
      "1 1\n",
      "18 18\n",
      "5 3\n",
      "9 9\n",
      "5 5\n",
      "6 6\n",
      "25 20\n",
      "17 16\n",
      "24 23\n",
      "20 18\n",
      "9 9\n",
      "23 22\n",
      "22 22\n",
      "18 15\n",
      "14 13\n",
      "27 27\n",
      "13 11\n",
      "8 8\n",
      "11 9\n",
      "7 6\n",
      "16 16\n",
      "26 26\n",
      "29 29\n",
      "7 5\n",
      "26 23\n",
      "5 5\n",
      "5 5\n",
      "21 19\n",
      "6 6\n",
      "5 5\n",
      "15 15\n",
      "7 7\n",
      "7 7\n",
      "7 7\n",
      "28 25\n",
      "19 17\n",
      "27 27\n",
      "10 9\n",
      "4 4\n",
      "12 11\n",
      "19 19\n",
      "6 6\n",
      "26 14\n",
      "31 26\n",
      "27 23\n",
      "5 4\n",
      "12 12\n",
      "6 5\n",
      "19 19\n",
      "13 11\n",
      "25 25\n",
      "10 10\n",
      "6 6\n",
      "6 6\n",
      "5 4\n",
      "30 26\n",
      "5 4\n",
      "9 9\n",
      "6 6\n",
      "5 3\n",
      "18 16\n",
      "16 12\n",
      "9 9\n",
      "14 13\n",
      "11 8\n",
      "21 21\n",
      "15 11\n",
      "10 10\n",
      "4 4\n",
      "3 2\n",
      "7 7\n",
      "13 11\n",
      "30 29\n",
      "17 17\n",
      "6 5\n",
      "19 14\n",
      "10 10\n",
      "8 8\n",
      "19 16\n",
      "29 28\n",
      "10 8\n",
      "5 5\n",
      "13 12\n",
      "24 21\n",
      "23 22\n",
      "10 8\n",
      "11 11\n",
      "8 8\n",
      "23 21\n",
      "44 42\n",
      "27 27\n",
      "25 21\n",
      "28 27\n",
      "5 5\n",
      "5 5\n",
      "18 15\n",
      "9 9\n",
      "20 13\n",
      "17 15\n",
      "6 6\n",
      "14 12\n",
      "19 18\n",
      "4 2\n",
      "8 8\n",
      "8 8\n",
      "10 9\n",
      "9 8\n",
      "9 9\n",
      "3 3\n",
      "17 16\n",
      "8 4\n",
      "27 27\n",
      "7 7\n",
      "7 7\n",
      "4 4\n",
      "13 13\n",
      "12 12\n",
      "7 7\n",
      "7 7\n",
      "6 6\n",
      "9 9\n",
      "15 14\n",
      "8 8\n",
      "3 3\n",
      "9 8\n",
      "23 20\n",
      "13 13\n",
      "10 10\n",
      "5 5\n",
      "21 14\n",
      "6 6\n",
      "5 5\n",
      "12 12\n",
      "5 5\n",
      "7 7\n",
      "9 7\n",
      "23 22\n",
      "12 11\n",
      "16 15\n",
      "10 9\n",
      "5 4\n",
      "21 21\n",
      "19 16\n",
      "18 17\n",
      "18 18\n",
      "3 1\n",
      "28 25\n",
      "10 10\n",
      "12 10\n",
      "4 4\n",
      "46 39\n",
      "13 13\n",
      "14 13\n",
      "3 3\n",
      "13 12\n",
      "46 46\n",
      "23 21\n",
      "11 11\n",
      "19 19\n",
      "15 12\n",
      "21 21\n",
      "24 22\n",
      "6 6\n",
      "27 24\n",
      "20 20\n",
      "27 25\n",
      "15 14\n",
      "11 10\n",
      "16 16\n",
      "6 5\n",
      "16 15\n",
      "27 27\n",
      "10 9\n",
      "26 19\n",
      "26 23\n",
      "8 8\n",
      "18 16\n",
      "23 22\n",
      "8 5\n",
      "13 12\n",
      "4 3\n",
      "6 6\n",
      "30 26\n",
      "6 6\n",
      "24 23\n",
      "25 24\n",
      "23 20\n",
      "20 15\n",
      "20 17\n",
      "4 4\n",
      "32 25\n",
      "5 3\n",
      "15 13\n",
      "6 5\n",
      "2 2\n",
      "25 23\n",
      "6 6\n",
      "7 6\n",
      "6 6\n",
      "5 5\n",
      "6 6\n",
      "35 35\n",
      "25 19\n",
      "7 7\n",
      "7 7\n",
      "31 31\n",
      "5 4\n",
      "27 25\n",
      "7 7\n",
      "14 11\n",
      "11 11\n",
      "14 13\n",
      "7 7\n",
      "15 15\n",
      "25 24\n",
      "21 20\n",
      "1 1\n",
      "28 28\n",
      "4 4\n",
      "28 25\n",
      "4 3\n",
      "25 24\n",
      "21 21\n",
      "8 7\n",
      "26 24\n",
      "10 9\n",
      "8 8\n",
      "21 21\n",
      "10 10\n",
      "35 28\n",
      "12 12\n",
      "20 19\n",
      "15 11\n",
      "4 4\n",
      "23 17\n",
      "35 34\n",
      "8 7\n",
      "13 12\n",
      "25 24\n",
      "16 15\n",
      "24 24\n",
      "4 4\n",
      "5 5\n",
      "5 5\n",
      "16 15\n",
      "8 6\n",
      "1 1\n",
      "4 4\n",
      "5 4\n",
      "13 10\n",
      "5 4\n",
      "5 5\n",
      "21 21\n",
      "11 9\n",
      "8 7\n",
      "8 7\n",
      "18 17\n",
      "11 11\n",
      "4 4\n",
      "29 28\n",
      "5 5\n",
      "27 22\n",
      "16 15\n",
      "9 9\n",
      "4 4\n",
      "20 18\n",
      "9 9\n",
      "21 18\n",
      "15 14\n",
      "5 5\n",
      "6 6\n",
      "13 13\n",
      "47 32\n",
      "7 6\n",
      "14 14\n",
      "23 21\n",
      "22 18\n",
      "5 5\n",
      "30 30\n",
      "14 14\n",
      "17 17\n",
      "23 22\n",
      "3 3\n",
      "7 7\n",
      "14 13\n",
      "2 2\n",
      "7 6\n",
      "17 17\n",
      "4 4\n",
      "29 27\n",
      "10 10\n",
      "12 12\n",
      "26 26\n",
      "20 16\n",
      "22 20\n",
      "5 5\n",
      "12 11\n",
      "4 3\n",
      "4 4\n",
      "60 60\n",
      "10 10\n",
      "25 24\n",
      "28 25\n",
      "5 5\n",
      "18 16\n",
      "11 11\n",
      "35 31\n",
      "8 7\n",
      "9 9\n",
      "7 5\n",
      "12 11\n",
      "8 8\n",
      "9 9\n",
      "22 19\n",
      "15 13\n",
      "25 23\n",
      "6 5\n",
      "13 12\n",
      "8 6\n",
      "25 25\n",
      "8 7\n",
      "6 5\n",
      "20 20\n",
      "6 6\n",
      "4 4\n",
      "16 15\n",
      "6 6\n",
      "21 19\n",
      "18 16\n",
      "18 16\n",
      "24 21\n",
      "7 7\n",
      "18 15\n",
      "24 23\n",
      "17 13\n",
      "7 5\n",
      "17 16\n",
      "15 11\n",
      "28 26\n",
      "9 9\n",
      "11 11\n",
      "20 18\n",
      "1 1\n",
      "20 20\n",
      "8 7\n",
      "8 8\n",
      "22 22\n",
      "21 20\n",
      "16 16\n",
      "9 9\n",
      "21 21\n",
      "17 15\n",
      "83 63\n",
      "26 21\n",
      "11 11\n",
      "12 10\n",
      "12 11\n",
      "8 6\n",
      "6 6\n",
      "22 22\n",
      "24 24\n",
      "7 7\n",
      "24 17\n",
      "1 1\n",
      "16 15\n",
      "7 6\n",
      "21 17\n",
      "19 19\n",
      "28 26\n",
      "8 6\n",
      "5 5\n",
      "37 32\n",
      "26 26\n",
      "6 6\n",
      "33 31\n",
      "20 18\n",
      "24 22\n",
      "26 25\n",
      "7 6\n",
      "15 15\n",
      "17 16\n",
      "7 7\n",
      "4 4\n",
      "22 19\n",
      "15 15\n",
      "8 8\n",
      "10 10\n",
      "32 25\n",
      "6 6\n",
      "16 16\n",
      "24 20\n",
      "15 15\n",
      "6 6\n",
      "24 20\n",
      "21 20\n",
      "6 5\n",
      "21 20\n",
      "11 11\n",
      "5 5\n",
      "21 21\n",
      "14 14\n",
      "7 7\n",
      "12 11\n",
      "25 24\n",
      "6 6\n",
      "8 7\n",
      "26 25\n",
      "21 20\n",
      "8 7\n",
      "23 23\n",
      "25 24\n",
      "24 20\n",
      "21 21\n",
      "5 5\n",
      "23 17\n",
      "26 26\n",
      "10 10\n",
      "6 5\n",
      "13 12\n",
      "6 6\n",
      "2 2\n",
      "25 24\n",
      "7 5\n",
      "15 14\n",
      "7 7\n",
      "16 15\n",
      "16 15\n",
      "23 22\n",
      "6 6\n",
      "6 6\n",
      "15 15\n",
      "10 10\n",
      "14 14\n",
      "23 22\n",
      "6 6\n",
      "14 14\n",
      "11 10\n",
      "10 9\n",
      "13 12\n",
      "8 8\n",
      "5 5\n",
      "15 15\n",
      "4 4\n",
      "27 25\n",
      "21 18\n",
      "9 8\n",
      "16 16\n",
      "44 41\n",
      "10 10\n",
      "31 31\n",
      "7 7\n",
      "20 16\n",
      "9 9\n",
      "7 7\n",
      "31 31\n",
      "20 20\n",
      "6 6\n",
      "24 23\n",
      "42 35\n",
      "2 2\n",
      "26 25\n",
      "16 16\n",
      "6 5\n",
      "5 5\n",
      "22 21\n",
      "13 11\n",
      "26 25\n",
      "11 10\n",
      "10 8\n",
      "6 6\n",
      "24 21\n",
      "17 13\n",
      "6 6\n",
      "21 17\n",
      "4 4\n",
      "14 14\n",
      "40 38\n",
      "5 4\n",
      "7 5\n",
      "9 9\n",
      "6 5\n",
      "3 3\n",
      "22 20\n",
      "8 8\n",
      "12 10\n",
      "26 24\n",
      "5 5\n",
      "19 16\n",
      "9 9\n",
      "15 15\n",
      "4 4\n",
      "9 9\n",
      "34 30\n",
      "18 16\n",
      "24 22\n",
      "12 12\n",
      "17 16\n",
      "5 3\n",
      "31 28\n",
      "23 23\n",
      "11 9\n",
      "50 43\n",
      "29 29\n",
      "13 13\n",
      "4 4\n",
      "24 15\n",
      "18 17\n",
      "14 14\n",
      "26 25\n",
      "6 6\n",
      "11 10\n",
      "8 8\n",
      "3 3\n",
      "19 14\n",
      "4 4\n",
      "15 13\n",
      "18 17\n",
      "17 16\n",
      "9 9\n",
      "4 2\n",
      "9 9\n",
      "4 4\n",
      "17 14\n",
      "16 16\n",
      "13 12\n",
      "17 16\n",
      "19 16\n",
      "9 9\n",
      "7 7\n",
      "8 8\n",
      "6 6\n",
      "6 5\n",
      "13 12\n",
      "21 19\n",
      "12 10\n",
      "10 10\n",
      "5 4\n",
      "19 19\n",
      "16 9\n",
      "8 7\n",
      "9 9\n",
      "8 7\n",
      "4 3\n",
      "4 3\n",
      "11 10\n",
      "25 24\n",
      "24 18\n",
      "49 43\n",
      "14 13\n",
      "8 8\n",
      "14 14\n",
      "5 5\n",
      "17 17\n",
      "6 6\n",
      "20 18\n",
      "20 15\n",
      "5 5\n",
      "7 7\n",
      "1 1\n",
      "8 6\n",
      "15 12\n",
      "13 7\n",
      "19 19\n",
      "17 17\n",
      "15 14\n",
      "42 38\n",
      "9 8\n",
      "17 13\n",
      "15 15\n",
      "16 14\n",
      "7 6\n",
      "15 13\n",
      "4 3\n",
      "24 23\n",
      "9 9\n",
      "5 5\n",
      "5 4\n",
      "6 5\n",
      "8 4\n",
      "31 28\n",
      "17 9\n",
      "8 8\n",
      "8 8\n",
      "16 16\n",
      "30 28\n",
      "6 6\n",
      "9 9\n",
      "5 5\n",
      "17 17\n",
      "18 15\n",
      "10 9\n",
      "27 24\n",
      "1 1\n",
      "4 3\n",
      "5 5\n",
      "14 14\n",
      "19 18\n",
      "25 12\n",
      "4 4\n",
      "13 13\n",
      "22 22\n",
      "25 25\n",
      "4 4\n",
      "24 24\n",
      "4 4\n",
      "17 15\n",
      "26 26\n",
      "11 11\n",
      "18 16\n",
      "3 3\n",
      "8 7\n",
      "6 6\n",
      "25 25\n",
      "19 19\n",
      "26 21\n",
      "6 6\n",
      "12 8\n",
      "25 25\n",
      "28 27\n",
      "7 7\n",
      "7 7\n",
      "9 7\n",
      "11 7\n",
      "14 5\n",
      "8 8\n",
      "7 7\n",
      "16 11\n",
      "19 17\n",
      "11 11\n",
      "6 4\n",
      "4 4\n",
      "6 6\n",
      "3 1\n",
      "11 9\n",
      "26 23\n",
      "9 9\n",
      "2 2\n",
      "70 66\n",
      "21 20\n",
      "17 11\n",
      "17 16\n",
      "18 16\n",
      "33 32\n",
      "5 5\n",
      "12 12\n",
      "6 6\n",
      "6 6\n",
      "11 11\n",
      "16 14\n",
      "7 6\n",
      "14 12\n",
      "10 10\n",
      "8 5\n",
      "9 9\n",
      "8 8\n",
      "24 20\n",
      "21 20\n",
      "5 5\n",
      "3 3\n",
      "11 10\n",
      "8 8\n",
      "26 26\n",
      "6 5\n",
      "7 7\n",
      "15 12\n",
      "21 18\n",
      "13 13\n",
      "6 6\n",
      "19 16\n",
      "23 21\n",
      "14 11\n",
      "29 28\n",
      "10 9\n",
      "8 8\n",
      "6 6\n",
      "14 14\n",
      "25 22\n",
      "16 16\n",
      "22 22\n",
      "5 5\n",
      "12 10\n",
      "7 6\n",
      "5 4\n",
      "7 7\n",
      "7 7\n",
      "16 15\n",
      "24 22\n",
      "8 7\n",
      "14 10\n",
      "7 6\n",
      "8 6\n",
      "7 7\n",
      "12 11\n",
      "8 8\n",
      "10 10\n",
      "5 5\n",
      "7 7\n",
      "7 7\n",
      "9 7\n",
      "7 7\n",
      "5 3\n",
      "26 22\n",
      "7 2\n",
      "14 14\n",
      "8 5\n",
      "3 2\n",
      "6 6\n",
      "26 21\n",
      "26 25\n",
      "9 7\n",
      "21 21\n",
      "4 4\n",
      "26 20\n",
      "7 5\n",
      "5 5\n",
      "25 25\n",
      "6 4\n",
      "9 8\n",
      "6 4\n",
      "26 26\n",
      "24 22\n",
      "30 30\n",
      "8 7\n",
      "29 27\n",
      "22 21\n",
      "12 9\n",
      "13 13\n",
      "19 17\n",
      "16 14\n",
      "8 8\n",
      "17 13\n",
      "7 7\n",
      "15 12\n",
      "29 26\n",
      "5 3\n",
      "17 15\n",
      "25 24\n",
      "11 11\n",
      "8 8\n",
      "23 20\n",
      "25 24\n",
      "6 5\n",
      "4 2\n",
      "23 17\n",
      "11 9\n",
      "19 17\n",
      "20 15\n",
      "22 20\n",
      "4 3\n",
      "10 10\n",
      "7 7\n",
      "8 6\n",
      "27 22\n",
      "5 5\n",
      "11 10\n",
      "11 10\n",
      "8 8\n",
      "6 5\n",
      "16 11\n",
      "27 26\n",
      "12 10\n",
      "20 17\n",
      "10 8\n",
      "5 4\n",
      "10 8\n",
      "9 9\n",
      "5 5\n",
      "7 7\n",
      "23 22\n",
      "4 1\n",
      "23 23\n",
      "6 6\n",
      "23 23\n",
      "6 5\n",
      "13 13\n",
      "7 5\n",
      "7 6\n",
      "17 11\n",
      "10 8\n",
      "6 6\n",
      "25 25\n",
      "19 19\n",
      "17 17\n",
      "25 23\n",
      "4 3\n"
     ]
    }
   ],
   "source": [
    "# notice that the sentence length is different than the length of the sentence vector\n",
    "for i,v in enumerate(w2v_vect):\n",
    "    print(len(X_test.iloc[i]), len(v))\n",
    "\n",
    "# each line in the loop has 2 numbers\n",
    "    # - length of the sentence from the test data\n",
    "    # - number/count of word vector for that exact sentence \n",
    "        # each vector having the length of 100 because that is number we set it to while creating the model\n",
    "\n",
    "        \n",
    "# we will get an error if we pass this to a model \n",
    "    # because the number of 'features' of the model has to be the same as the number(len) that goes into the model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# element-wise average\n",
    "# we will store the first entry of the first sentence in the vector\n",
    "\n",
    "# for each array in the w2v_vector array\n",
    "    # make sure that at least one word has a word vector\n",
    "    # take that array of word vectors\n",
    "    # calculate the element-wise average of those word vectors\n",
    "    # and append it to the w2v_vect_avg LIST of our final vectors\n",
    "    \n",
    "    # in case that there are no word vector for a certain sentence\n",
    "        # this means that we have no understanding of that text message\n",
    "        # create an array with len==100 that is full of zeros\n",
    "        # and append it to w2v_vect_avg\n",
    "\n",
    "w2v_vect_avg = []\n",
    "\n",
    "for vect in w2v_vect:\n",
    "    if len(vect) != 0:\n",
    "        w2v_vect_avg.append(vect.mean(axis=0))\n",
    "    else:\n",
    "        w2v_vect_avg.append(np.zeros(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 100\n",
      "6 100\n",
      "15 100\n",
      "22 100\n",
      "7 100\n",
      "23 100\n",
      "20 100\n",
      "8 100\n",
      "8 100\n",
      "7 100\n",
      "17 100\n",
      "5 100\n",
      "10 100\n",
      "5 100\n",
      "16 100\n",
      "9 100\n",
      "9 100\n",
      "6 100\n",
      "15 100\n",
      "7 100\n",
      "2 100\n",
      "7 100\n",
      "11 100\n",
      "20 100\n",
      "18 100\n",
      "14 100\n",
      "9 100\n",
      "5 100\n",
      "4 100\n",
      "5 100\n",
      "21 100\n",
      "16 100\n",
      "20 100\n",
      "8 100\n",
      "8 100\n",
      "13 100\n",
      "13 100\n",
      "26 100\n",
      "4 100\n",
      "9 100\n",
      "20 100\n",
      "6 100\n",
      "22 100\n",
      "27 100\n",
      "5 100\n",
      "26 100\n",
      "31 100\n",
      "6 100\n",
      "24 100\n",
      "20 100\n",
      "30 100\n",
      "20 100\n",
      "11 100\n",
      "25 100\n",
      "7 100\n",
      "7 100\n",
      "5 100\n",
      "30 100\n",
      "5 100\n",
      "16 100\n",
      "10 100\n",
      "19 100\n",
      "8 100\n",
      "7 100\n",
      "9 100\n",
      "8 100\n",
      "19 100\n",
      "15 100\n",
      "25 100\n",
      "24 100\n",
      "13 100\n",
      "17 100\n",
      "13 100\n",
      "17 100\n",
      "19 100\n",
      "6 100\n",
      "12 100\n",
      "4 100\n",
      "31 100\n",
      "7 100\n",
      "22 100\n",
      "13 100\n",
      "15 100\n",
      "7 100\n",
      "5 100\n",
      "13 100\n",
      "27 100\n",
      "12 100\n",
      "5 100\n",
      "9 100\n",
      "17 100\n",
      "5 100\n",
      "5 100\n",
      "4 100\n",
      "22 100\n",
      "13 100\n",
      "5 100\n",
      "14 100\n",
      "8 100\n",
      "6 100\n",
      "8 100\n",
      "1 100\n",
      "5 100\n",
      "18 100\n",
      "13 100\n",
      "2 100\n",
      "11 100\n",
      "3 100\n",
      "5 100\n",
      "18 100\n",
      "10 100\n",
      "27 100\n",
      "7 100\n",
      "10 100\n",
      "3 100\n",
      "4 100\n",
      "20 100\n",
      "4 100\n",
      "12 100\n",
      "4 100\n",
      "1 100\n",
      "7 100\n",
      "4 100\n",
      "22 100\n",
      "29 100\n",
      "5 100\n",
      "5 100\n",
      "11 100\n",
      "46 100\n",
      "12 100\n",
      "21 100\n",
      "11 100\n",
      "1 100\n",
      "5 100\n",
      "24 100\n",
      "11 100\n",
      "4 100\n",
      "6 100\n",
      "16 100\n",
      "6 100\n",
      "3 100\n",
      "8 100\n",
      "8 100\n",
      "16 100\n",
      "25 100\n",
      "6 100\n",
      "9 100\n",
      "25 100\n",
      "22 100\n",
      "6 100\n",
      "14 100\n",
      "7 100\n",
      "19 100\n",
      "26 100\n",
      "20 100\n",
      "52 100\n",
      "5 100\n",
      "12 100\n",
      "5 100\n",
      "22 100\n",
      "6 100\n",
      "22 100\n",
      "22 100\n",
      "17 100\n",
      "22 100\n",
      "5 100\n",
      "27 100\n",
      "9 100\n",
      "11 100\n",
      "22 100\n",
      "9 100\n",
      "36 100\n",
      "6 100\n",
      "6 100\n",
      "6 100\n",
      "23 100\n",
      "15 100\n",
      "4 100\n",
      "22 100\n",
      "19 100\n",
      "24 100\n",
      "2 100\n",
      "6 100\n",
      "36 100\n",
      "25 100\n",
      "7 100\n",
      "25 100\n",
      "9 100\n",
      "7 100\n",
      "18 100\n",
      "7 100\n",
      "8 100\n",
      "5 100\n",
      "24 100\n",
      "6 100\n",
      "7 100\n",
      "4 100\n",
      "13 100\n",
      "6 100\n",
      "22 100\n",
      "30 100\n",
      "28 100\n",
      "18 100\n",
      "14 100\n",
      "39 100\n",
      "11 100\n",
      "8 100\n",
      "4 100\n",
      "11 100\n",
      "14 100\n",
      "8 100\n",
      "9 100\n",
      "15 100\n",
      "8 100\n",
      "6 100\n",
      "8 100\n",
      "6 100\n",
      "27 100\n",
      "18 100\n",
      "11 100\n",
      "21 100\n",
      "26 100\n",
      "31 100\n",
      "6 100\n",
      "54 100\n",
      "19 100\n",
      "7 100\n",
      "9 100\n",
      "5 100\n",
      "20 100\n",
      "30 100\n",
      "14 100\n",
      "18 100\n",
      "26 100\n",
      "3 100\n",
      "6 100\n",
      "31 100\n",
      "1 100\n",
      "8 100\n",
      "16 100\n",
      "16 100\n",
      "14 100\n",
      "37 100\n",
      "25 100\n",
      "5 100\n",
      "29 100\n",
      "6 100\n",
      "8 100\n",
      "25 100\n",
      "3 100\n",
      "39 100\n",
      "8 100\n",
      "6 100\n",
      "30 100\n",
      "25 100\n",
      "16 100\n",
      "6 100\n",
      "27 100\n",
      "7 100\n",
      "11 100\n",
      "5 100\n",
      "6 100\n",
      "4 100\n",
      "8 100\n",
      "6 100\n",
      "13 100\n",
      "9 100\n",
      "5 100\n",
      "11 100\n",
      "5 100\n",
      "16 100\n",
      "4 100\n",
      "18 100\n",
      "9 100\n",
      "12 100\n",
      "3 100\n",
      "5 100\n",
      "4 100\n",
      "21 100\n",
      "9 100\n",
      "23 100\n",
      "8 100\n",
      "5 100\n",
      "4 100\n",
      "21 100\n",
      "36 100\n",
      "20 100\n",
      "14 100\n",
      "9 100\n",
      "2 100\n",
      "6 100\n",
      "19 100\n",
      "26 100\n",
      "23 100\n",
      "8 100\n",
      "21 100\n",
      "17 100\n",
      "24 100\n",
      "5 100\n",
      "10 100\n",
      "25 100\n",
      "14 100\n",
      "12 100\n",
      "14 100\n",
      "27 100\n",
      "8 100\n",
      "13 100\n",
      "5 100\n",
      "14 100\n",
      "19 100\n",
      "6 100\n",
      "22 100\n",
      "8 100\n",
      "9 100\n",
      "4 100\n",
      "4 100\n",
      "30 100\n",
      "8 100\n",
      "24 100\n",
      "6 100\n",
      "30 100\n",
      "21 100\n",
      "8 100\n",
      "4 100\n",
      "23 100\n",
      "4 100\n",
      "56 100\n",
      "14 100\n",
      "22 100\n",
      "5 100\n",
      "1 100\n",
      "18 100\n",
      "5 100\n",
      "9 100\n",
      "5 100\n",
      "6 100\n",
      "25 100\n",
      "17 100\n",
      "24 100\n",
      "20 100\n",
      "9 100\n",
      "23 100\n",
      "22 100\n",
      "18 100\n",
      "14 100\n",
      "27 100\n",
      "13 100\n",
      "8 100\n",
      "11 100\n",
      "7 100\n",
      "16 100\n",
      "26 100\n",
      "29 100\n",
      "7 100\n",
      "26 100\n",
      "5 100\n",
      "5 100\n",
      "21 100\n",
      "6 100\n",
      "5 100\n",
      "15 100\n",
      "7 100\n",
      "7 100\n",
      "7 100\n",
      "28 100\n",
      "19 100\n",
      "27 100\n",
      "10 100\n",
      "4 100\n",
      "12 100\n",
      "19 100\n",
      "6 100\n",
      "26 100\n",
      "31 100\n",
      "27 100\n",
      "5 100\n",
      "12 100\n",
      "6 100\n",
      "19 100\n",
      "13 100\n",
      "25 100\n",
      "10 100\n",
      "6 100\n",
      "6 100\n",
      "5 100\n",
      "30 100\n",
      "5 100\n",
      "9 100\n",
      "6 100\n",
      "5 100\n",
      "18 100\n",
      "16 100\n",
      "9 100\n",
      "14 100\n",
      "11 100\n",
      "21 100\n",
      "15 100\n",
      "10 100\n",
      "4 100\n",
      "3 100\n",
      "7 100\n",
      "13 100\n",
      "30 100\n",
      "17 100\n",
      "6 100\n",
      "19 100\n",
      "10 100\n",
      "8 100\n",
      "19 100\n",
      "29 100\n",
      "10 100\n",
      "5 100\n",
      "13 100\n",
      "24 100\n",
      "23 100\n",
      "10 100\n",
      "11 100\n",
      "8 100\n",
      "23 100\n",
      "44 100\n",
      "27 100\n",
      "25 100\n",
      "28 100\n",
      "5 100\n",
      "5 100\n",
      "18 100\n",
      "9 100\n",
      "20 100\n",
      "17 100\n",
      "6 100\n",
      "14 100\n",
      "19 100\n",
      "4 100\n",
      "8 100\n",
      "8 100\n",
      "10 100\n",
      "9 100\n",
      "9 100\n",
      "3 100\n",
      "17 100\n",
      "8 100\n",
      "27 100\n",
      "7 100\n",
      "7 100\n",
      "4 100\n",
      "13 100\n",
      "12 100\n",
      "7 100\n",
      "7 100\n",
      "6 100\n",
      "9 100\n",
      "15 100\n",
      "8 100\n",
      "3 100\n",
      "9 100\n",
      "23 100\n",
      "13 100\n",
      "10 100\n",
      "5 100\n",
      "21 100\n",
      "6 100\n",
      "5 100\n",
      "12 100\n",
      "5 100\n",
      "7 100\n",
      "9 100\n",
      "23 100\n",
      "12 100\n",
      "16 100\n",
      "10 100\n",
      "5 100\n",
      "21 100\n",
      "19 100\n",
      "18 100\n",
      "18 100\n",
      "3 100\n",
      "28 100\n",
      "10 100\n",
      "12 100\n",
      "4 100\n",
      "46 100\n",
      "13 100\n",
      "14 100\n",
      "3 100\n",
      "13 100\n",
      "46 100\n",
      "23 100\n",
      "11 100\n",
      "19 100\n",
      "15 100\n",
      "21 100\n",
      "24 100\n",
      "6 100\n",
      "27 100\n",
      "20 100\n",
      "27 100\n",
      "15 100\n",
      "11 100\n",
      "16 100\n",
      "6 100\n",
      "16 100\n",
      "27 100\n",
      "10 100\n",
      "26 100\n",
      "26 100\n",
      "8 100\n",
      "18 100\n",
      "23 100\n",
      "8 100\n",
      "13 100\n",
      "4 100\n",
      "6 100\n",
      "30 100\n",
      "6 100\n",
      "24 100\n",
      "25 100\n",
      "23 100\n",
      "20 100\n",
      "20 100\n",
      "4 100\n",
      "32 100\n",
      "5 100\n",
      "15 100\n",
      "6 100\n",
      "2 100\n",
      "25 100\n",
      "6 100\n",
      "7 100\n",
      "6 100\n",
      "5 100\n",
      "6 100\n",
      "35 100\n",
      "25 100\n",
      "7 100\n",
      "7 100\n",
      "31 100\n",
      "5 100\n",
      "27 100\n",
      "7 100\n",
      "14 100\n",
      "11 100\n",
      "14 100\n",
      "7 100\n",
      "15 100\n",
      "25 100\n",
      "21 100\n",
      "1 100\n",
      "28 100\n",
      "4 100\n",
      "28 100\n",
      "4 100\n",
      "25 100\n",
      "21 100\n",
      "8 100\n",
      "26 100\n",
      "10 100\n",
      "8 100\n",
      "21 100\n",
      "10 100\n",
      "35 100\n",
      "12 100\n",
      "20 100\n",
      "15 100\n",
      "4 100\n",
      "23 100\n",
      "35 100\n",
      "8 100\n",
      "13 100\n",
      "25 100\n",
      "16 100\n",
      "24 100\n",
      "4 100\n",
      "5 100\n",
      "5 100\n",
      "16 100\n",
      "8 100\n",
      "1 100\n",
      "4 100\n",
      "5 100\n",
      "13 100\n",
      "5 100\n",
      "5 100\n",
      "21 100\n",
      "11 100\n",
      "8 100\n",
      "8 100\n",
      "18 100\n",
      "11 100\n",
      "4 100\n",
      "29 100\n",
      "5 100\n",
      "27 100\n",
      "16 100\n",
      "9 100\n",
      "4 100\n",
      "20 100\n",
      "9 100\n",
      "21 100\n",
      "15 100\n",
      "5 100\n",
      "6 100\n",
      "13 100\n",
      "47 100\n",
      "7 100\n",
      "14 100\n",
      "23 100\n",
      "22 100\n",
      "5 100\n",
      "30 100\n",
      "14 100\n",
      "17 100\n",
      "23 100\n",
      "3 100\n",
      "7 100\n",
      "14 100\n",
      "2 100\n",
      "7 100\n",
      "17 100\n",
      "4 100\n",
      "29 100\n",
      "10 100\n",
      "12 100\n",
      "26 100\n",
      "20 100\n",
      "22 100\n",
      "5 100\n",
      "12 100\n",
      "4 100\n",
      "4 100\n",
      "60 100\n",
      "10 100\n",
      "25 100\n",
      "28 100\n",
      "5 100\n",
      "18 100\n",
      "11 100\n",
      "35 100\n",
      "8 100\n",
      "9 100\n",
      "7 100\n",
      "12 100\n",
      "8 100\n",
      "9 100\n",
      "22 100\n",
      "15 100\n",
      "25 100\n",
      "6 100\n",
      "13 100\n",
      "8 100\n",
      "25 100\n",
      "8 100\n",
      "6 100\n",
      "20 100\n",
      "6 100\n",
      "4 100\n",
      "16 100\n",
      "6 100\n",
      "21 100\n",
      "18 100\n",
      "18 100\n",
      "24 100\n",
      "7 100\n",
      "18 100\n",
      "24 100\n",
      "17 100\n",
      "7 100\n",
      "17 100\n",
      "15 100\n",
      "28 100\n",
      "9 100\n",
      "11 100\n",
      "20 100\n",
      "1 100\n",
      "20 100\n",
      "8 100\n",
      "8 100\n",
      "22 100\n",
      "21 100\n",
      "16 100\n",
      "9 100\n",
      "21 100\n",
      "17 100\n",
      "83 100\n",
      "26 100\n",
      "11 100\n",
      "12 100\n",
      "12 100\n",
      "8 100\n",
      "6 100\n",
      "22 100\n",
      "24 100\n",
      "7 100\n",
      "24 100\n",
      "1 100\n",
      "16 100\n",
      "7 100\n",
      "21 100\n",
      "19 100\n",
      "28 100\n",
      "8 100\n",
      "5 100\n",
      "37 100\n",
      "26 100\n",
      "6 100\n",
      "33 100\n",
      "20 100\n",
      "24 100\n",
      "26 100\n",
      "7 100\n",
      "15 100\n",
      "17 100\n",
      "7 100\n",
      "4 100\n",
      "22 100\n",
      "15 100\n",
      "8 100\n",
      "10 100\n",
      "32 100\n",
      "6 100\n",
      "16 100\n",
      "24 100\n",
      "15 100\n",
      "6 100\n",
      "24 100\n",
      "21 100\n",
      "6 100\n",
      "21 100\n",
      "11 100\n",
      "5 100\n",
      "21 100\n",
      "14 100\n",
      "7 100\n",
      "12 100\n",
      "25 100\n",
      "6 100\n",
      "8 100\n",
      "26 100\n",
      "21 100\n",
      "8 100\n",
      "23 100\n",
      "25 100\n",
      "24 100\n",
      "21 100\n",
      "5 100\n",
      "23 100\n",
      "26 100\n",
      "10 100\n",
      "6 100\n",
      "13 100\n",
      "6 100\n",
      "2 100\n",
      "25 100\n",
      "7 100\n",
      "15 100\n",
      "7 100\n",
      "16 100\n",
      "16 100\n",
      "23 100\n",
      "6 100\n",
      "6 100\n",
      "15 100\n",
      "10 100\n",
      "14 100\n",
      "23 100\n",
      "6 100\n",
      "14 100\n",
      "11 100\n",
      "10 100\n",
      "13 100\n",
      "8 100\n",
      "5 100\n",
      "15 100\n",
      "4 100\n",
      "27 100\n",
      "21 100\n",
      "9 100\n",
      "16 100\n",
      "44 100\n",
      "10 100\n",
      "31 100\n",
      "7 100\n",
      "20 100\n",
      "9 100\n",
      "7 100\n",
      "31 100\n",
      "20 100\n",
      "6 100\n",
      "24 100\n",
      "42 100\n",
      "2 100\n",
      "26 100\n",
      "16 100\n",
      "6 100\n",
      "5 100\n",
      "22 100\n",
      "13 100\n",
      "26 100\n",
      "11 100\n",
      "10 100\n",
      "6 100\n",
      "24 100\n",
      "17 100\n",
      "6 100\n",
      "21 100\n",
      "4 100\n",
      "14 100\n",
      "40 100\n",
      "5 100\n",
      "7 100\n",
      "9 100\n",
      "6 100\n",
      "3 100\n",
      "22 100\n",
      "8 100\n",
      "12 100\n",
      "26 100\n",
      "5 100\n",
      "19 100\n",
      "9 100\n",
      "15 100\n",
      "4 100\n",
      "9 100\n",
      "34 100\n",
      "18 100\n",
      "24 100\n",
      "12 100\n",
      "17 100\n",
      "5 100\n",
      "31 100\n",
      "23 100\n",
      "11 100\n",
      "50 100\n",
      "29 100\n",
      "13 100\n",
      "4 100\n",
      "24 100\n",
      "18 100\n",
      "14 100\n",
      "26 100\n",
      "6 100\n",
      "11 100\n",
      "8 100\n",
      "3 100\n",
      "19 100\n",
      "4 100\n",
      "15 100\n",
      "18 100\n",
      "17 100\n",
      "9 100\n",
      "4 100\n",
      "9 100\n",
      "4 100\n",
      "17 100\n",
      "16 100\n",
      "13 100\n",
      "17 100\n",
      "19 100\n",
      "9 100\n",
      "7 100\n",
      "8 100\n",
      "6 100\n",
      "6 100\n",
      "13 100\n",
      "21 100\n",
      "12 100\n",
      "10 100\n",
      "5 100\n",
      "19 100\n",
      "16 100\n",
      "8 100\n",
      "9 100\n",
      "8 100\n",
      "4 100\n",
      "4 100\n",
      "11 100\n",
      "25 100\n",
      "24 100\n",
      "49 100\n",
      "14 100\n",
      "8 100\n",
      "14 100\n",
      "5 100\n",
      "17 100\n",
      "6 100\n",
      "20 100\n",
      "20 100\n",
      "5 100\n",
      "7 100\n",
      "1 100\n",
      "8 100\n",
      "15 100\n",
      "13 100\n",
      "19 100\n",
      "17 100\n",
      "15 100\n",
      "42 100\n",
      "9 100\n",
      "17 100\n",
      "15 100\n",
      "16 100\n",
      "7 100\n",
      "15 100\n",
      "4 100\n",
      "24 100\n",
      "9 100\n",
      "5 100\n",
      "5 100\n",
      "6 100\n",
      "8 100\n",
      "31 100\n",
      "17 100\n",
      "8 100\n",
      "8 100\n",
      "16 100\n",
      "30 100\n",
      "6 100\n",
      "9 100\n",
      "5 100\n",
      "17 100\n",
      "18 100\n",
      "10 100\n",
      "27 100\n",
      "1 100\n",
      "4 100\n",
      "5 100\n",
      "14 100\n",
      "19 100\n",
      "25 100\n",
      "4 100\n",
      "13 100\n",
      "22 100\n",
      "25 100\n",
      "4 100\n",
      "24 100\n",
      "4 100\n",
      "17 100\n",
      "26 100\n",
      "11 100\n",
      "18 100\n",
      "3 100\n",
      "8 100\n",
      "6 100\n",
      "25 100\n",
      "19 100\n",
      "26 100\n",
      "6 100\n",
      "12 100\n",
      "25 100\n",
      "28 100\n",
      "7 100\n",
      "7 100\n",
      "9 100\n",
      "11 100\n",
      "14 100\n",
      "8 100\n",
      "7 100\n",
      "16 100\n",
      "19 100\n",
      "11 100\n",
      "6 100\n",
      "4 100\n",
      "6 100\n",
      "3 100\n",
      "11 100\n",
      "26 100\n",
      "9 100\n",
      "2 100\n",
      "70 100\n",
      "21 100\n",
      "17 100\n",
      "17 100\n",
      "18 100\n",
      "33 100\n",
      "5 100\n",
      "12 100\n",
      "6 100\n",
      "6 100\n",
      "11 100\n",
      "16 100\n",
      "7 100\n",
      "14 100\n",
      "10 100\n",
      "8 100\n",
      "9 100\n",
      "8 100\n",
      "24 100\n",
      "21 100\n",
      "5 100\n",
      "3 100\n",
      "11 100\n",
      "8 100\n",
      "26 100\n",
      "6 100\n",
      "7 100\n",
      "15 100\n",
      "21 100\n",
      "13 100\n",
      "6 100\n",
      "19 100\n",
      "23 100\n",
      "14 100\n",
      "29 100\n",
      "10 100\n",
      "8 100\n",
      "6 100\n",
      "14 100\n",
      "25 100\n",
      "16 100\n",
      "22 100\n",
      "5 100\n",
      "12 100\n",
      "7 100\n",
      "5 100\n",
      "7 100\n",
      "7 100\n",
      "16 100\n",
      "24 100\n",
      "8 100\n",
      "14 100\n",
      "7 100\n",
      "8 100\n",
      "7 100\n",
      "12 100\n",
      "8 100\n",
      "10 100\n",
      "5 100\n",
      "7 100\n",
      "7 100\n",
      "9 100\n",
      "7 100\n",
      "5 100\n",
      "26 100\n",
      "7 100\n",
      "14 100\n",
      "8 100\n",
      "3 100\n",
      "6 100\n",
      "26 100\n",
      "26 100\n",
      "9 100\n",
      "21 100\n",
      "4 100\n",
      "26 100\n",
      "7 100\n",
      "5 100\n",
      "25 100\n",
      "6 100\n",
      "9 100\n",
      "6 100\n",
      "26 100\n",
      "24 100\n",
      "30 100\n",
      "8 100\n",
      "29 100\n",
      "22 100\n",
      "12 100\n",
      "13 100\n",
      "19 100\n",
      "16 100\n",
      "8 100\n",
      "17 100\n",
      "7 100\n",
      "15 100\n",
      "29 100\n",
      "5 100\n",
      "17 100\n",
      "25 100\n",
      "11 100\n",
      "8 100\n",
      "23 100\n",
      "25 100\n",
      "6 100\n",
      "4 100\n",
      "23 100\n",
      "11 100\n",
      "19 100\n",
      "20 100\n",
      "22 100\n",
      "4 100\n",
      "10 100\n",
      "7 100\n",
      "8 100\n",
      "27 100\n",
      "5 100\n",
      "11 100\n",
      "11 100\n",
      "8 100\n",
      "6 100\n",
      "16 100\n",
      "27 100\n",
      "12 100\n",
      "20 100\n",
      "10 100\n",
      "5 100\n",
      "10 100\n",
      "9 100\n",
      "5 100\n",
      "7 100\n",
      "23 100\n",
      "4 100\n",
      "23 100\n",
      "6 100\n",
      "23 100\n",
      "6 100\n",
      "13 100\n",
      "7 100\n",
      "7 100\n",
      "17 100\n",
      "10 100\n",
      "6 100\n",
      "25 100\n",
      "19 100\n",
      "17 100\n",
      "25 100\n",
      "4 100\n"
     ]
    }
   ],
   "source": [
    "# now check if the lengths match \n",
    "for i,v in enumerate(w2v_vect_avg):\n",
    "    print(len(X_test.iloc[i]), len(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ---> now each sentence is represented with one vector \n",
    "    - (that has an average value of the individual word vectors for words in that sentence)\n",
    "    - with length set to 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------\n",
    "\n",
    "## doc2vec \n",
    "- creates a vector on a sentence/paragraph/document level\n",
    "- a two-layer neural network (the same as word2vec)\n",
    "- skips the consolidation step we had to do previously (creating vectors for each individual word and then averaging the values of those vectors to represent a single sentence)\n",
    "    - averaging a group of numbers to represent a single number will result in **information loss**\n",
    "    - doc2vec represents the sentence/paragraph/document in a more sophisticated way\n",
    "- usage:\n",
    "    1. using pretrained embeddings\n",
    "    2. training models with our own data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "data = pd.read_csv('dataset/SMSSpamCollection.csv', sep='delimiter')\n",
    "messages = pd.DataFrame(columns=['label','text'])\n",
    "messages[['label','text']] = data['v1\\tv2'].str.split('\\t', expand=True)\n",
    "\n",
    "# print(messages.head())\n",
    "\n",
    "messages['text_clean'] = messages['text'].apply(lambda x: gensim.utils.simple_preprocess(x))\n",
    "\n",
    "print(messages.head())\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    messages['text_clean'],\n",
    "    messages['label'],\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### doc2vec will provide a 'tag' attribute for each individual sentence\n",
    "\n",
    "tagged_docs = [gensim.models.doc2vec.TaggedDocument(v, [i]) for i,v in enumerate(X_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['studying', 'in', 'sch', 'or', 'going', 'home', 'anyway', 'll', 'going', 'sch', 'later'], tags=[16])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_docs[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training a doc2vec model\n",
    "d2v_model = gensim.models.Doc2Vec(tagged_docs,\n",
    "                                 vector_size=100,\n",
    "                                 window=5,\n",
    "                                 min_count=2\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Parameter doc_words of infer_vector() must be a list of strings (not a single string).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-e26d2549f5a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# we HAVE to pass in a list of strings to the results of the trained model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0md2v_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfer_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\nlp_lipik\\lib\\site-packages\\gensim\\models\\doc2vec.py\u001b[0m in \u001b[0;36minfer_vector\u001b[1;34m(self, doc_words, alpha, min_alpha, epochs, steps)\u001b[0m\n\u001b[0;32m    660\u001b[0m         \"\"\"\n\u001b[0;32m    661\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 662\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Parameter doc_words of infer_vector() must be a list of strings (not a single string).\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    663\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    664\u001b[0m         \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Parameter doc_words of infer_vector() must be a list of strings (not a single string)."
     ]
    }
   ],
   "source": [
    "# we HAVE to pass in a list of strings to the results of the trained model\n",
    "d2v_model.infer_vector('text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00141423,  0.0062188 ,  0.00308266,  0.00276783, -0.00383873,\n",
       "        0.00274167,  0.00401915, -0.00190763, -0.00608317, -0.00218049,\n",
       "        0.00775998,  0.00343144, -0.00045128,  0.00121614, -0.00130062,\n",
       "       -0.00188033, -0.01035386, -0.00589644, -0.00275047,  0.0015035 ,\n",
       "       -0.00376079, -0.00450834, -0.00075878, -0.00467609,  0.00075025,\n",
       "       -0.00409629,  0.00276235,  0.00145573,  0.00304923, -0.00255933,\n",
       "        0.00616254, -0.00497567, -0.00277544,  0.00393416, -0.00028814,\n",
       "       -0.00058989,  0.00654795, -0.00163432,  0.00279466,  0.00311303,\n",
       "        0.00337751,  0.00144811,  0.00300472, -0.00054887,  0.00136764,\n",
       "        0.00908081, -0.00327512, -0.00262275,  0.0019084 ,  0.00550525,\n",
       "       -0.00374384,  0.00442728,  0.00263951, -0.0033929 , -0.01222997,\n",
       "        0.00108002,  0.00553672,  0.00742503, -0.00937249,  0.00564457,\n",
       "       -0.00440077, -0.00125692,  0.00596297, -0.00120858, -0.00029843,\n",
       "       -0.00034503, -0.01143269, -0.00682692,  0.00635015,  0.00378877,\n",
       "       -0.01314945,  0.00180165, -0.00660685,  0.01501286, -0.00064648,\n",
       "        0.00592671,  0.00261555,  0.0012774 , -0.0022606 , -0.00524561,\n",
       "       -0.00538058, -0.00243498,  0.00513968,  0.00987108, -0.00201743,\n",
       "       -0.00188388,  0.00807188,  0.0092803 ,  0.00371492,  0.00323677,\n",
       "        0.01010347,  0.00341798,  0.00534954,  0.008326  , -0.00835319,\n",
       "        0.01108018,  0.00412627,  0.00505297, -0.00103648, -0.01398334],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2v_model.infer_vector(['text', 'data', 'from', 'NLP', 'doc2vec', 'model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the length of each vector is 100 (that is the parameter we have passed while instantiating a traning Doc2Vec model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### now the vectors should be prepared for a machine learning model\n",
    "# first we iterate through lists of words from X_test\n",
    "# then we pass those lists of words (see above) to the 'infer_vector' attribute\n",
    "# then, the resulting arrays of vectors SHOULD be stored in a LIST called 'vectors'\n",
    "    # we do not have to store it to an array like in the word2vec model,\n",
    "    # because we do not have to calculate element-wise average values and fix the lengths of the vectors\n",
    "    \n",
    "vectors = [[d2v_model.infer_vector(words)] for words in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.00480069,  0.01078585,  0.0060761 , -0.00832097, -0.02767451,\n",
       "         0.00116301,  0.00923245, -0.00837996, -0.02789045,  0.00531719,\n",
       "         0.00519943,  0.01568944, -0.00407802,  0.00488987,  0.00735666,\n",
       "        -0.01594962, -0.02276433, -0.01023729, -0.01090279,  0.00674385,\n",
       "        -0.02333922, -0.0038877 ,  0.02124634, -0.00444617, -0.00241868,\n",
       "        -0.02987038,  0.00992619, -0.0067247 ,  0.00316342,  0.00367629,\n",
       "         0.02253664, -0.02524848, -0.01193742,  0.02027621, -0.01742133,\n",
       "         0.01005882,  0.02816904,  0.00826702, -0.00741691, -0.00880202,\n",
       "         0.00470332,  0.00971489,  0.01717932, -0.01005577, -0.00371203,\n",
       "         0.02099204, -0.01884709, -0.02261822,  0.00820917,  0.00743707,\n",
       "        -0.00432223,  0.00670638, -0.00100442, -0.02463825, -0.04387959,\n",
       "        -0.00503191,  0.00306877,  0.01743518, -0.03731865,  0.02951704,\n",
       "        -0.0084368 , -0.00396591,  0.01556264, -0.00605551,  0.0124385 ,\n",
       "         0.00183623, -0.03845953, -0.01010414,  0.02927699, -0.00300889,\n",
       "        -0.03854078, -0.01025888, -0.02572769,  0.03677407,  0.00835737,\n",
       "         0.01663241,  0.0092323 , -0.00582974, -0.00777409, -0.00755247,\n",
       "        -0.01419997,  0.01264507,  0.04164656,  0.03218353, -0.01425762,\n",
       "         0.00261286,  0.0116555 ,  0.02318673, -0.00253543, -0.00964708,\n",
       "         0.03904816,  0.01576235, -0.00113255,  0.0161127 , -0.02002959,\n",
       "         0.02626569,  0.0223724 ,  0.02241589,  0.00108986, -0.04655984],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors[128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
